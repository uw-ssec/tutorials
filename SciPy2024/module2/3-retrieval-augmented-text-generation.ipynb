{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "707e2ebc-4325-4ed0-b99c-89fade3153fb",
   "metadata": {},
   "source": [
    "# Retrieval-Augmented Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "581812da-03d2-407a-aff9-fa621946a81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import langchain\n",
    "import textwrap\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "613b678f-c0a6-4847-9e5f-cd1712e4b6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain_community.llms import LlamaCpp\n",
    "from langchain_core.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_qdrant import Qdrant\n",
    "from langchain_huggingface import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ebe7a6ca-3fe6-48d3-b7e0-f2571e673479",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cpp import Llama\n",
    "from scipy import spatial\n",
    "from qdrant_client import QdrantClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b138cc6d-9ee7-41d6-996b-66eeae9e3c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ssec_tutorials import OLMO_MODEL, QDRANT_PATH, QDRANT_COLLECTION_NAME, download_qdrant_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09859839-902b-4fd4-8b4a-69ce5c41a05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08fde1b-f2a4-4c57-8a94-c3dd58a10d74",
   "metadata": {},
   "source": [
    "Although trained on large datasets, stale data can severely limit LLMs. It faces several challenges:\n",
    "\n",
    "1. The models are trained on internet content, so they might not generate relevant output when prompted for information that is not publicly available on the internet.\n",
    "\n",
    "2. The models are trained up to a certain date, they might not generate relevant output when prompted for content and information that has happened after the training completion date of the model.\n",
    "\n",
    "3. The models are trained to be more generalized. This means that they can only produce generic outputs and might not perform as expected when prompted for specific deep-dive concepts related to a particular topic.\n",
    "\n",
    "One way to dynamically integrate relevant external information is retrieval-augmented generation (RAG), which can help improve the reliability of LLM outputs. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e8f06f-b377-4280-9a35-0d2c832904d4",
   "metadata": {},
   "source": [
    "## RAG Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb892294-f03e-4ad5-9e7b-269526de7a36",
   "metadata": {},
   "source": [
    "RAG proposes a solution to this issue by supplementing the prompt sent to the LLM with information from external sources through a retrieval model, thereby providing the LLM with more relevant input to generation responses. It allows you to use pre-trained LLMs without fine-tuning them or training your own LLM on your training data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a045f318-5226-4023-a301-4617299c6b21",
   "metadata": {},
   "source": [
    "![RAG Workflow](../../images/rag-workflow.webp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f220bf9c-6378-4dcc-acb0-dfa32000db77",
   "metadata": {},
   "source": [
    "\n",
    "Image Source: [Medium Blog](https://medium.com/@henryhengluo/intro-of-retrieval-augmented-generation-rag-and-application-demos-c1d9239ababf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0430de73-e46c-4029-a460-dbc65184208c",
   "metadata": {},
   "source": [
    "Multiple concepts influence RAG pipeline:\n",
    "\n",
    "1. Retrieval\n",
    "2. Augmentation\n",
    "3. Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4855b786-5d33-4e4c-b58c-ab8c039deae8",
   "metadata": {},
   "source": [
    "## Retrieval\n",
    "\n",
    "The retrieval phase can also be considered the data and query/prompt preparation phase, focusing on efficient information retrieval or data access. To improve your RAG pipeline, the pre-retrieval phase contains tasks such as: `(1): Indexing, (2) Query Manipulation, (3) Data Modification, (4) Search, and (5) Ranking.` In this tutorial, we primarily focus on indexing and search. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37abe984-c0d4-4b22-b74e-f3b00bbe0260",
   "metadata": {},
   "source": [
    "`Indexing` enables fast and accurate information retrieval that sets up the context for any LLM to improve its response to a given user prompt or query. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6beb0cdf-ac35-4546-90c5-fd8082633ca5",
   "metadata": {},
   "source": [
    "We will be indexing abstracts for all astrophysics papers and Astropy's documentation, a common core package for Astronomy in Python. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bbcf1d-499d-4b82-ab23-205ee6d078d3",
   "metadata": {},
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86537e0-7c49-43c7-b985-f028b9036c46",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "Embeddings, also called \"Vector Embedding,\" help LLMs develop a semantic understanding of the textual data they are trained on. In simpler terms, these embedding models lay the groundwork for LLMs to perform tasks like sentence completion, similarity search, questions and answers, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a048945d-c67d-4ecd-ae07-57f694a5ec52",
   "metadata": {},
   "source": [
    "#### Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab12955-0056-409d-b23a-af27a48dd29d",
   "metadata": {},
   "source": [
    "At the lowest level, machines only understand numeric values. For LLMs to work, natural language is converted into an array of numeric values before they are fed into the models. These arrays of numeric values are called \"Vector.\"\n",
    "\n",
    "An example of a vector: [2.5, 1.0, 3.3, 7.8]\n",
    "\n",
    "The above is an example of a vector of size 4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a00edab-f0e2-4ac4-b9a9-d64f1f0adc28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector: [2.5 1.7 3.3 7.8]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "vector = np.array([2.5, 1.7, 3.3, 7.8])\n",
    "print(f\"Vector: {vector}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ad8341-6516-4a1a-aab7-ea14cb5a53cc",
   "metadata": {},
   "source": [
    "#### Tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fec2773-b602-457c-a674-d70bf2971dea",
   "metadata": {},
   "source": [
    "We stated above that **\"texts are converted into an array of numeric values called vectors\"**.\n",
    "\n",
    "But depending on your use case, each word, sentence, paragraph, or entire document can be represented as a vector. \n",
    "\n",
    "Tokens are the smallest natural language units converted into a vector. It could be at the character level, sub-word level, word level, sentence level, paragraph level, or document level.\n",
    "\n",
    "Example: Consider the text below.\n",
    "\n",
    "`Earth is a planet of the solar system. There are 9 planets in the solar system. \n",
    "All planets revolve around the sun. Sun is a star.`\n",
    "\n",
    "\n",
    "Case 1.) **Tokenizing the entire paragraph into vector.**  \n",
    "Tokenization: The entire paragraph is a single token.   \n",
    "Vectorization: A single vector.  \n",
    "Sample Vector Representation: [3.1, 6.8, 5.4, 8.0, 7.1]\n",
    "\n",
    "Case 2.) **Tokenizing each sentence into vectors.**  \n",
    "Tokenization: One token for each sentence (total 4 tokens)  \n",
    "Vectorization: One vector for each sentence (total 4 vectors).   \n",
    "Sample Vector Representation: [[1.2, 2.3, 3.8, 7.9, 0.8], [2.5, 3.0, 8.2, 6.6, 4.1], [3.2, 6.5, 8.1, 9.3, 1.4], [1.1, 0.7, 7.2, 3.5, 8.5]]\n",
    "\n",
    "Case 3.) **Tokenizing each word in the paragraph into a vector. There are 26 words in the paragraph, ignoring punctuation. Each word gets converted into a vector.**  \n",
    "Tokenization: One token for each word in the paragraph (26 tokens)  \n",
    "Vectorization: One vector for each token (total 26 vectors).    \n",
    "Sample Vector Representation: [[2.1, 3.2, 4.1, 9.8, 7.0], [8.2, 4.2, 7.1, 3.8, 2.0].....total 26 such represenatations]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a97f481-33c8-4672-a16c-308e7a6f2dc9",
   "metadata": {},
   "source": [
    "#### Tokenizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b06b3dc-e387-417c-aec9-01044b5f6a56",
   "metadata": {},
   "source": [
    "Tokenizers are components responsible for converting large texts into tokens (tokenization). Different types of pre-trained tokenizers are available. You can even train your own tokenizers. But for the scope of this tutorial, we will use a pre-trained one. \n",
    "\n",
    "Generally, each tokenizer follows the following steps:\n",
    "\n",
    "1. Break down the original text into tokens. These tokens could again be at the character, sub-word, word, sentence, paragraph, or document levels.\n",
    "2. Assign a unique identifier to each of the tokens created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84e2701b-d65f-46b4-a84e-940cfc89df6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For example, here is how you can split a short sentence into chunks of text\n",
    "from langchain_text_splitters import CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da90bd59-5295-40c4-98c6-fe5c6bdb9d58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Earth is a', 'planet in', 'the solar', 'system.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\" \",\n",
    "    chunk_size=10,\n",
    "    chunk_overlap=0,\n",
    ")\n",
    "text_splitter.split_text(text=\"Earth is a planet in the solar system.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f6605b-d212-45c2-89b3-54cf3eba5303",
   "metadata": {},
   "source": [
    "[Learn more about how to split text into tokens in LangChain here.](https://python.langchain.com/v0.2/docs/how_to/split_by_token/) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1176aa-6658-43d8-b3d5-c02ff4827690",
   "metadata": {},
   "source": [
    "#### Embedding Models\n",
    "\n",
    "A language model needs to understand how tokens are related to each other in the context of human language. To understand this semantic relationship, these tokens are converted into numerical vectors.\n",
    "\n",
    "Embedding Models are trained upon these tokens to develop an \"embedding space.\"\n",
    "\n",
    "- Before the training, the embedding model initializes an N-dimensional 'vector' corresponding to each 'token' with random values. (Value of N depends on the embedding model)\n",
    "  \n",
    "- During the embedding model training, the values for these vectors are updated across iterations. In this process, similar or related tokens are updated to have similarly valued vectors.\n",
    "  \n",
    "- After the training, the collection of all the 'vectors' corresponding to all the tokens is called the \"embedding space.\"\n",
    "\n",
    "- \"Embedding Space\" is an encoded representation of meanings of tokens and inter-token relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b9d732-fd39-4292-b68d-570888409d27",
   "metadata": {},
   "source": [
    "> We now embed our relevant documents (knowledge base) into a pre-trained embedding model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b5a5e70-60a5-4270-b58c-b2f69e724193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the embedding, we are using the MiniLM model here\n",
    "embeddings_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L12-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e3beed7-0042-4142-9226-8371ee2ef38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_result = embeddings_model.embed_query(\"Earth is a planet in the solar system.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe1a2a99-c7a6-45c0-879d-e3ca7f69cc61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dimension of vector\n",
    "len(query_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31a6277c-fbb7-44ff-a1c0-1a78c4cf545e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.05409970134496689, 0.07589352875947952, -0.04195248335599899]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_result[-3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb6a255-2c4a-4a6e-ad53-cd7865c2165e",
   "metadata": {},
   "source": [
    "In an embedding space, you can find how similar two vectors are using `dot product` or  using `cosine similarity.`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "93157aff-f521-474b-9202-36fccb7bdb70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.7926038246541188\n"
     ]
    }
   ],
   "source": [
    "print(\"Similarity:\", 1 - spatial.distance.cosine(query_result, embeddings_model.embed_query(\"Mars is a planet in the solar system.\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "044ccda7-acfe-406d-a5a9-a9c30f6390cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.08770955995845531\n"
     ]
    }
   ],
   "source": [
    "print(\"Similarity:\", 1 - spatial.distance.cosine(query_result, embeddings_model.embed_query(\"Hello Tacoma.\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f92142a-c8e4-4421-aa16-809d8b1ad4e0",
   "metadata": {},
   "source": [
    "#### Vector Stores\n",
    "\n",
    "Once the embeddings are created for our relevant documents or knowledge base, we need to store these embeddings in the database for fast retrieval. \n",
    "\n",
    "The type of databases that store these vector embeddings are called \"Vector Stores.\" We will use a vector store called \"Qdrant,\" as shown below. \n",
    "\n",
    "In the below code, \n",
    "- Vector store works along with the embedding model to create vector embeddings.\n",
    "- Vector embeddings are stored in the Qdrant Vector database collection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f07ea7d-cd51-470c-867a-e9c0aa36cf84",
   "metadata": {},
   "source": [
    "We have already created a vector database that contains the astrophysics paper abstracts and Astropy's documentation, please refer to the notebook in the Appendix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "80088e8e-83df-498b-80ec-3f5ff787c5f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qdrant data already exists at /Users/a42/.cache/ssec_tutorials/scipy_qdrant\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/a42/.cache/ssec_tutorials/scipy_qdrant')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download_qdrant_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f5991dd1-d360-4d90-9fca-1ba0a13bd1a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/a42/.cache/ssec_tutorials/scipy_qdrant')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QDRANT_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "868cec4d-ce4d-455f-9704-4a0616093290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arxiv_astro-ph_abstracts_astropy_github_documentation'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QDRANT_COLLECTION_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "69ea8e13-73b0-43ed-b705-26205f4de4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing Qdrant collection 'arxiv_astro-ph_abstracts_astropy_github_documentation'\n"
     ]
    }
   ],
   "source": [
    "# Setting up Qdrant\n",
    "if os.path.exists(QDRANT_PATH):\n",
    "    print(f\"Loading existing Qdrant collection '{QDRANT_COLLECTION_NAME}'\")\n",
    "    \n",
    "    client = QdrantClient(path=QDRANT_PATH)\n",
    "    \n",
    "    qdrant = Qdrant(\n",
    "        client=client,\n",
    "        collection_name=QDRANT_COLLECTION_NAME,\n",
    "        embeddings=embeddings_model\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522b1723-0992-4d47-86c5-24b04d816df6",
   "metadata": {},
   "source": [
    "### Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e2a98db8-dead-44c7-a26b-0d0d5319d904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the retriever for later step\n",
    "# mmr stands for  Maximum Marginal Relevance \n",
    "# \"MMR selects examples based on a combination of which examples are most similar to the inputs, while also optimizing for diversity. It does this by finding the examples with the embeddings that have the greatest cosine similarity with the inputs, and then iteratively adding them while penalizing them for closeness to already selected examples.\"\n",
    "retriever = qdrant.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "469ce9c5-ce25-41c3-a836-db7df31c3bd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='  I give a review of the development of the concept of dark matter. The dark\\nmatter story passed through several stages from a minor observational puzzle to\\na major challenge for theory of elementary particles. Modern data suggest that\\ndark matter is the dominant matter component in the Universe, and that it\\nconsists of some unknown non-baryonic particles. Properties of dark matter\\nparticles determine the structure of the cosmic web.\\n', metadata={'id': 1109.558, 'title': 'Dark matter', '_id': '363091ccc8f643fa9b51eed9aa157ad9', '_collection_name': 'arxiv_astro-ph_abstracts_astropy_github_documentation'}),\n",
       " Document(page_content='  Even though there are strong astrophysical and cosmological indications to\\nsupport the existence of dark matter, its exact nature remains unknown. We\\nexpect dark matter to produce standard model particles when annihilating or\\ndecaying, assuming that it is composed of Weakly Interacting Massive Particles\\n(WIMPs). These standard model particles could in turn yield neutrinos that can\\nbe detected by the IceCube neutrino telescope. The Milky Way is expected to be\\npermeated by a dark matter halo with an increased density towards its centre.\\nThis halo is expected to yield the strongest dark matter annihilation signal at\\nEarth coming from any celestial object, making it an ideal target for indirect\\nsearches. In this contribution, we present the sensitivities of an indirect\\nsearch for dark matter in the Galactic Centre using IceCube data. This low\\nenergy dark matter search allows us to cover dark matter masses ranging from 5\\nGeV to 1 TeV. The sensitivities obtained for this analysis show considerable\\nimprovements over previous IceCube results in the considered energy range.\\n', metadata={'id': 2107.11224, 'title': 'Indirect search for dark matter in the Galactic Centre with IceCube', '_id': '54e8d56798d04046b498f599970cdb79', '_collection_name': 'arxiv_astro-ph_abstracts_astropy_github_documentation'})]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"What is dark matter?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8ff3542b-4469-4432-befb-6f3b725a3c2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='.. _astropy-coordinates-transforming:\\n\\nTransforming between Systems\\n****************************\\n\\n`astropy.coordinates` supports a rich system for transforming\\ncoordinates from one frame to another. While common astronomy frames\\nare built into Astropy, the transformation infrastructure is dynamic.\\nThis means it allows users to define new coordinate frames and their\\ntransformations. The topic of writing your own coordinate frame or\\ntransforms is detailed in :ref:`astropy-coordinates-design`, and this\\nsection is focused on how to *use* transformations.\\n\\nThe full list of built-in coordinate frames, the included transformations,\\nand the frame names are shown as a (clickable) graph in the\\n`~astropy.coordinates` API documentation.\\n\\nExamples\\n--------\\n\\n..\\n  EXAMPLE START\\n  Transforming Coordinates to Another Frame\\n\\nThe recommended method of transformation is shown below::\\n\\n    >>> import astropy.units as u\\n    >>> from astropy.coordinates import SkyCoord\\n    >>> gc = SkyCoord(l=0*u.degree, b=45*u.degree, frame=\\'galactic\\')\\n    >>> gc.fk5  # doctest: +FLOAT_CMP\\n    <SkyCoord (FK5: equinox=J2000.000): (ra, dec) in deg\\n        ( 229.27251463, -1.12844288)>\\n\\nWhile this appears to be ordinary attribute-style access, it is actually\\nsyntactic sugar for the more general\\n:meth:`~astropy.coordinates.SkyCoord.transform_to` method, which can\\naccept either a frame name, class, or instance::\\n\\n    >>> from astropy.coordinates import FK5\\n    >>> gc.transform_to(\\'fk5\\')  # doctest: +FLOAT_CMP\\n    <SkyCoord (FK5: equinox=J2000.000): (ra, dec) in deg\\n        ( 229.27251463, -1.12844288)>\\n    >>> gc.transform_to(FK5)  # doctest: +FLOAT_CMP\\n    <SkyCoord (FK5: equinox=J2000.000): (ra, dec) in deg\\n        ( 229.27251463, -1.12844288)>\\n    >>> gc.transform_to(FK5(equinox=\\'J1980.0\\'))  # doctest: +FLOAT_CMP\\n    <SkyCoord (FK5: equinox=J1980.000): (ra, dec) in deg\\n        ( 229.0146935, -1.05560349)>\\n\\n..\\n  EXAMPLE END\\n\\n..\\n  EXAMPLE START\\n  Using SkyCoord Objects as the Frame in Transformations\\n\\nAs a convenience, it is also possible to use a |SkyCoord| object as the frame in\\n:meth:`~astropy.coordinates.SkyCoord.transform_to`. This allows for putting one\\ncoordinate object into the frame of another::\\n\\n    >>> sc = SkyCoord(ra=1.0, dec=2.0, unit=\\'deg\\', frame=FK5, equinox=\\'J1980.0\\')\\n    >>> gc.transform_to(sc)  # doctest: +FLOAT_CMP\\n    <SkyCoord (FK5: equinox=J1980.000): (ra, dec) in deg\\n        ( 229.0146935, -1.05560349)>\\n\\n..\\n  EXAMPLE END\\n\\n..\\n  EXAMPLE START\\n  Self Transformations of Coordinate Frames\\n\\nSome coordinate frames (including `~astropy.coordinates.FK5`,\\n`~astropy.coordinates.FK4`, and `~astropy.coordinates.FK4NoETerms`) support\\n\"self transformations,\" meaning the *type* of frame does not change, but the\\nframe attributes do. An example is precessing a coordinate from one equinox\\nto another in an equatorial frame. This is done by passing ``transform_to`` a\\nframe class with the relevant attributes, as shown below. Note that these\\nframes use a default equinox if you do not specify one::\\n\\n    >>> fk5c = SkyCoord(\\'02h31m49.09s\\', \\'+89d15m50.8s\\', frame=FK5)\\n    >>> fk5c.equinox\\n    <Time object: scale=\\'tt\\' format=\\'jyear_str\\' value=J2000.000>\\n    >>> fk5c  # doctest: +FLOAT_CMP\\n    <SkyCoord (FK5: equinox=J2000.000): (ra, dec) in deg\\n        ( 37.95454167,  89.26411111)>\\n    >>> fk5_2005 = FK5(equinox=\\'J2005\\')  # String initializes an astropy.time.Time object\\n    >>> fk5c.transform_to(fk5_2005)  # doctest: +FLOAT_CMP\\n    <SkyCoord (FK5: equinox=J2005.000): (ra, dec) in deg\\n        ( 39.39317639,  89.28584422)>\\n\\nYou can also specify the equinox when you create a coordinate using a\\n`~astropy.time.Time` object::\\n\\n    >>> from astropy.time import Time\\n    >>> fk5c = SkyCoord(\\'02h31m49.09s\\', \\'+89d15m50.8s\\',\\n    ...                 frame=FK5(equinox=Time(\\'J1970\\')))\\n    >>> fk5_2000 = FK5(equinox=Time(2000, format=\\'jyear\\'))\\n    >>> fk5c.transform_to(fk5_2000)  # doctest: +FLOAT_CMP\\n    <SkyCoord (FK5: equinox=2000.0): (ra, dec) in deg\\n        ( 48.023171,  89.38672485)>\\n\\nThe same lower-level frame classes also have a\\n:meth:`~astropy.coordinates.BaseCoordinateFrame.transform_to` method\\nthat works the same as above, but they do not support attribute-style\\naccess. They are also subtly different in that they only use frame\\nattributes present in the initial or final frame, while |SkyCoord|\\nobjects use any frame attributes they have for all transformation\\nsteps. So |SkyCoord| can always transform from one frame to another and\\nback again without change, while low-level classes may lose information\\nand hence often do not round-trip.\\n\\n..\\n  EXAMPLE END\\n\\n.. _astropy-coordinates-transforming-ephemerides:\\n\\nTransformations and Solar System Ephemerides\\n============================================\\n\\nSome transformations (e.g., the transformation between\\n`~astropy.coordinates.ICRS` and `~astropy.coordinates.GCRS`) require the use of\\na Solar System ephemeris to calculate the position and velocity of the Earth\\nand Sun. By default, transformations are calculated using built-in\\n`ERFA <https://github.com/liberfa/erfa>`_ routines, but they can also use more\\nprecise ones using the JPL ephemerides (which are derived from dynamical\\nmodels).\\n\\nExample\\n-------\\n\\n..\\n  EXAMPLE START\\n  Calculating Transformations Using Solar System Ephemeris\\n\\nTo use the JPL ephemerides, use the\\n`~astropy.coordinates.solar_system_ephemeris` context manager, as shown below:\\n\\n.. doctest-requires:: jplephem\\n\\n    >>> from astropy.coordinates import solar_system_ephemeris\\n    >>> from astropy.coordinates import GCRS\\n    >>> with solar_system_ephemeris.set(\\'jpl\\'): # doctest: +REMOTE_DATA +IGNORE_OUTPUT\\n    ...     fk5c.transform_to(GCRS(obstime=Time(\"J2000\"))) # doctest: +REMOTE_DATA +IGNORE_OUTPUT\\n\\nFor locations at large distances from the Solar system, using the JPL\\nephemerides will make a negligible difference on the order of micro-arcseconds.\\nFor nearby objects, such as the Moon, the difference can be of the\\norder of milli-arcseconds. For more details about what ephemerides\\nare available, including the requirements for using JPL ephemerides, see\\n:ref:`astropy-coordinates-solarsystem`.\\n\\n..\\n  EXAMPLE END\\n', metadata={'title': 'Transforming', 'url': 'https://raw.githubusercontent.com/astropy/astropy/main/docs/coordinates/transforming.rst', '_id': 'b8c6a3090a4346fe948426dedab611cd', '_collection_name': 'arxiv_astro-ph_abstracts_astropy_github_documentation'}),\n",
       " Document(page_content='  In Paper I, Greisen & Calabretta (2002) describe a generalized method for\\nassigning physical coordinates to FITS image pixels. This paper implements this\\nmethod for all spherical map projections likely to be of interest in astronomy.\\nThe new methods encompass existing informal FITS spherical coordinate\\nconventions and translations from them are described. Detailed examples of\\nheader interpretation and construction are given.\\n', metadata={'id': 'astro-ph/0207413', 'title': 'Representations of celestial coordinates in FITS', '_id': 'fc988d45866549c4ae09bed143c04b6d', '_collection_name': 'arxiv_astro-ph_abstracts_astropy_github_documentation'})]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"How can I perform celestial coordinate transformations?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "41a270b6-05a0-4f3f-80a1-21b7f98cca91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post-processing\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ec307d1d-8e83-45f9-8048-43c07974a24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  I give a review of the development of the concept of dark matter. The dark\n",
      "matter story passed through several stages from a minor observational puzzle to\n",
      "a major challenge for theory of elementary particles. Modern data suggest that\n",
      "dark matter is the dominant matter component in the Universe, and that it\n",
      "consists of some unknown non-baryonic particles. Properties of dark matter\n",
      "particles determine the structure of the cosmic web.\n",
      "\n",
      "\n",
      "  Even though there are strong astrophysical and cosmological indications to\n",
      "support the existence of dark matter, its exact nature remains unknown. We\n",
      "expect dark matter to produce standard model particles when annihilating or\n",
      "decaying, assuming that it is composed of Weakly Interacting Massive Particles\n",
      "(WIMPs). These standard model particles could in turn yield neutrinos that can\n",
      "be detected by the IceCube neutrino telescope. The Milky Way is expected to be\n",
      "permeated by a dark matter halo with an increased density towards its centre.\n",
      "This halo is expected to yield the strongest dark matter annihilation signal at\n",
      "Earth coming from any celestial object, making it an ideal target for indirect\n",
      "searches. In this contribution, we present the sensitivities of an indirect\n",
      "search for dark matter in the Galactic Centre using IceCube data. This low\n",
      "energy dark matter search allows us to cover dark matter masses ranging from 5\n",
      "GeV to 1 TeV. The sensitivities obtained for this analysis show considerable\n",
      "improvements over previous IceCube results in the considered energy range.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(format_docs(retriever.invoke(\"What is dark matter?\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f90230bb-b3fe-47a1-954d-e38ff39c35ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _astropy-coordinates-transforming:\n",
      "\n",
      "Transforming between Systems\n",
      "****************************\n",
      "\n",
      "`astropy.coordinates` supports a rich system for transforming\n",
      "coordinates from one frame to another. While common astronomy frames\n",
      "are built into Astropy, the transformation infrastructure is dynamic.\n",
      "This means it allows users to define new coordinate frames and their\n",
      "transformations. The topic of writing your own coordinate frame or\n",
      "transforms is detailed in :ref:`astropy-coordinates-design`, and this\n",
      "section is focused on how to *use* transformations.\n",
      "\n",
      "The full list of built-in coordinate frames, the included transformations,\n",
      "and the frame names are shown as a (clickable) graph in the\n",
      "`~astropy.coordinates` API documentation.\n",
      "\n",
      "Examples\n",
      "--------\n",
      "\n",
      "..\n",
      "  EXAMPLE START\n",
      "  Transforming Coordinates to Another Frame\n",
      "\n",
      "The recommended method of transformation is shown below::\n",
      "\n",
      "    >>> import astropy.units as u\n",
      "    >>> from astropy.coordinates import SkyCoord\n",
      "    >>> gc = SkyCoord(l=0*u.degree, b=45*u.degree, frame='galactic')\n",
      "    >>> gc.fk5  # doctest: +FLOAT_CMP\n",
      "    <SkyCoord (FK5: equinox=J2000.000): (ra, dec) in deg\n",
      "        ( 229.27251463, -1.12844288)>\n",
      "\n",
      "While this appears to be ordinary attribute-style access, it is actually\n",
      "syntactic sugar for the more general\n",
      ":meth:`~astropy.coordinates.SkyCoord.transform_to` method, which can\n",
      "accept either a frame name, class, or instance::\n",
      "\n",
      "    >>> from astropy.coordinates import FK5\n",
      "    >>> gc.transform_to('fk5')  # doctest: +FLOAT_CMP\n",
      "    <SkyCoord (FK5: equinox=J2000.000): (ra, dec) in deg\n",
      "        ( 229.27251463, -1.12844288)>\n",
      "    >>> gc.transform_to(FK5)  # doctest: +FLOAT_CMP\n",
      "    <SkyCoord (FK5: equinox=J2000.000): (ra, dec) in deg\n",
      "        ( 229.27251463, -1.12844288)>\n",
      "    >>> gc.transform_to(FK5(equinox='J1980.0'))  # doctest: +FLOAT_CMP\n",
      "    <SkyCoord (FK5: equinox=J1980.000): (ra, dec) in deg\n",
      "        ( 229.0146935, -1.05560349)>\n",
      "\n",
      "..\n",
      "  EXAMPLE END\n",
      "\n",
      "..\n",
      "  EXAMPLE START\n",
      "  Using SkyCoord Objects as the Frame in Transformations\n",
      "\n",
      "As a convenience, it is also possible to use a |SkyCoord| object as the frame in\n",
      ":meth:`~astropy.coordinates.SkyCoord.transform_to`. This allows for putting one\n",
      "coordinate object into the frame of another::\n",
      "\n",
      "    >>> sc = SkyCoord(ra=1.0, dec=2.0, unit='deg', frame=FK5, equinox='J1980.0')\n",
      "    >>> gc.transform_to(sc)  # doctest: +FLOAT_CMP\n",
      "    <SkyCoord (FK5: equinox=J1980.000): (ra, dec) in deg\n",
      "        ( 229.0146935, -1.05560349)>\n",
      "\n",
      "..\n",
      "  EXAMPLE END\n",
      "\n",
      "..\n",
      "  EXAMPLE START\n",
      "  Self Transformations of Coordinate Frames\n",
      "\n",
      "Some coordinate frames (including `~astropy.coordinates.FK5`,\n",
      "`~astropy.coordinates.FK4`, and `~astropy.coordinates.FK4NoETerms`) support\n",
      "\"self transformations,\" meaning the *type* of frame does not change, but the\n",
      "frame attributes do. An example is precessing a coordinate from one equinox\n",
      "to another in an equatorial frame. This is done by passing ``transform_to`` a\n",
      "frame class with the relevant attributes, as shown below. Note that these\n",
      "frames use a default equinox if you do not specify one::\n",
      "\n",
      "    >>> fk5c = SkyCoord('02h31m49.09s', '+89d15m50.8s', frame=FK5)\n",
      "    >>> fk5c.equinox\n",
      "    <Time object: scale='tt' format='jyear_str' value=J2000.000>\n",
      "    >>> fk5c  # doctest: +FLOAT_CMP\n",
      "    <SkyCoord (FK5: equinox=J2000.000): (ra, dec) in deg\n",
      "        ( 37.95454167,  89.26411111)>\n",
      "    >>> fk5_2005 = FK5(equinox='J2005')  # String initializes an astropy.time.Time object\n",
      "    >>> fk5c.transform_to(fk5_2005)  # doctest: +FLOAT_CMP\n",
      "    <SkyCoord (FK5: equinox=J2005.000): (ra, dec) in deg\n",
      "        ( 39.39317639,  89.28584422)>\n",
      "\n",
      "You can also specify the equinox when you create a coordinate using a\n",
      "`~astropy.time.Time` object::\n",
      "\n",
      "    >>> from astropy.time import Time\n",
      "    >>> fk5c = SkyCoord('02h31m49.09s', '+89d15m50.8s',\n",
      "    ...                 frame=FK5(equinox=Time('J1970')))\n",
      "    >>> fk5_2000 = FK5(equinox=Time(2000, format='jyear'))\n",
      "    >>> fk5c.transform_to(fk5_2000)  # doctest: +FLOAT_CMP\n",
      "    <SkyCoord (FK5: equinox=2000.0): (ra, dec) in deg\n",
      "        ( 48.023171,  89.38672485)>\n",
      "\n",
      "The same lower-level frame classes also have a\n",
      ":meth:`~astropy.coordinates.BaseCoordinateFrame.transform_to` method\n",
      "that works the same as above, but they do not support attribute-style\n",
      "access. They are also subtly different in that they only use frame\n",
      "attributes present in the initial or final frame, while |SkyCoord|\n",
      "objects use any frame attributes they have for all transformation\n",
      "steps. So |SkyCoord| can always transform from one frame to another and\n",
      "back again without change, while low-level classes may lose information\n",
      "and hence often do not round-trip.\n",
      "\n",
      "..\n",
      "  EXAMPLE END\n",
      "\n",
      ".. _astropy-coordinates-transforming-ephemerides:\n",
      "\n",
      "Transformations and Solar System Ephemerides\n",
      "============================================\n",
      "\n",
      "Some transformations (e.g., the transformation between\n",
      "`~astropy.coordinates.ICRS` and `~astropy.coordinates.GCRS`) require the use of\n",
      "a Solar System ephemeris to calculate the position and velocity of the Earth\n",
      "and Sun. By default, transformations are calculated using built-in\n",
      "`ERFA <https://github.com/liberfa/erfa>`_ routines, but they can also use more\n",
      "precise ones using the JPL ephemerides (which are derived from dynamical\n",
      "models).\n",
      "\n",
      "Example\n",
      "-------\n",
      "\n",
      "..\n",
      "  EXAMPLE START\n",
      "  Calculating Transformations Using Solar System Ephemeris\n",
      "\n",
      "To use the JPL ephemerides, use the\n",
      "`~astropy.coordinates.solar_system_ephemeris` context manager, as shown below:\n",
      "\n",
      ".. doctest-requires:: jplephem\n",
      "\n",
      "    >>> from astropy.coordinates import solar_system_ephemeris\n",
      "    >>> from astropy.coordinates import GCRS\n",
      "    >>> with solar_system_ephemeris.set('jpl'): # doctest: +REMOTE_DATA +IGNORE_OUTPUT\n",
      "    ...     fk5c.transform_to(GCRS(obstime=Time(\"J2000\"))) # doctest: +REMOTE_DATA +IGNORE_OUTPUT\n",
      "\n",
      "For locations at large distances from the Solar system, using the JPL\n",
      "ephemerides will make a negligible difference on the order of micro-arcseconds.\n",
      "For nearby objects, such as the Moon, the difference can be of the\n",
      "order of milli-arcseconds. For more details about what ephemerides\n",
      "are available, including the requirements for using JPL ephemerides, see\n",
      ":ref:`astropy-coordinates-solarsystem`.\n",
      "\n",
      "..\n",
      "  EXAMPLE END\n",
      "\n",
      "\n",
      "  In Paper I, Greisen & Calabretta (2002) describe a generalized method for\n",
      "assigning physical coordinates to FITS image pixels. This paper implements this\n",
      "method for all spherical map projections likely to be of interest in astronomy.\n",
      "The new methods encompass existing informal FITS spherical coordinate\n",
      "conventions and translations from them are described. Detailed examples of\n",
      "header interpretation and construction are given.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(format_docs(retriever.invoke(\"How can I perform celestial coordinate transformations?\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9260d5b4-b95c-4e76-804b-e4ed69492313",
   "metadata": {},
   "source": [
    "## Augmentation & Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff927dd-8eb3-4632-88b6-9a04e9907cb5",
   "metadata": {},
   "source": [
    "Now that we can retrieve the most relevant document based on a question, we can use the retrieved document and send it along with the prompt to increase the context for the LLM.\n",
    "\n",
    "This can also be referred to as the `retrieval-augmented prompt.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e0afedaa-feb8-4d6f-9adc-85694008967f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "olmo = LlamaCpp(\n",
    "    model_path=str(OLMO_MODEL),\n",
    "    temperature=0.8,\n",
    "    verbose=False,  \n",
    "    n_ctx=2048,\n",
    "    max_tokens=512,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "da3e6e4f-a9c9-4634-8004-761a54727d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a prompt template using OLMo's tokenizer chat template we saw in module 1.\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    template=olmo.client.metadata['tokenizer.chat_template'], \n",
    "    template_format=\"jinja2\",\n",
    "    partial_variables={\"add_generation_prompt\": True, \"eos_token\": \"<|endoftext|>\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5b0976d6-392e-440a-b929-a95e4daa13df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['messages'], partial_variables={'add_generation_prompt': True, 'eos_token': '<|endoftext|>'}, template=\"{{ eos_token }}{% for message in messages %}\\n{% if message['role'] == 'user' %}\\n{{ '<|user|>\\n' + message['content'] }}\\n{% elif message['role'] == 'assistant' %}\\n{{ '<|assistant|>\\n'  + message['content'] + eos_token }}\\n{% endif %}\\n{% if loop.last and add_generation_prompt %}\\n{{ '<|assistant|>' }}\\n{% endif %}\\n{% endfor %}\", template_format='jinja2')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0d8458f5-24db-47bc-9cc5-81162f581e94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|endoftext|>\\n\\n<|user|>\\nYou are an astrophysics expert. Please answer the question on astrophysics based on the following context:\\n\\n            Context:   I give a review of the development of the concept of dark matter. The dark\\nmatter story passed through several stages from a minor observational puzzle to\\na major challenge for theory of elementary particles. Modern data suggest that\\ndark matter is the dominant matter component in the Universe, and that it\\nconsists of some unknown non-baryonic particles. Properties of dark matter\\nparticles determine the structure of the cosmic web.\\n\\n\\n  Even though there are strong astrophysical and cosmological indications to\\nsupport the existence of dark matter, its exact nature remains unknown. We\\nexpect dark matter to produce standard model particles when annihilating or\\ndecaying, assuming that it is composed of Weakly Interacting Massive Particles\\n(WIMPs). These standard model particles could in turn yield neutrinos that can\\nbe detected by the IceCube neutrino telescope. The Milky Way is expected to be\\npermeated by a dark matter halo with an increased density towards its centre.\\nThis halo is expected to yield the strongest dark matter annihilation signal at\\nEarth coming from any celestial object, making it an ideal target for indirect\\nsearches. In this contribution, we present the sensitivities of an indirect\\nsearch for dark matter in the Galactic Centre using IceCube data. This low\\nenergy dark matter search allows us to cover dark matter masses ranging from 5\\nGeV to 1 TeV. The sensitivities obtained for this analysis show considerable\\nimprovements over previous IceCube results in the considered energy range.\\n\\n            \\n            Question: What is dark matter?\\n\\n\\n<|assistant|>\\n\\n'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the prompt you want to send to OLMo.\n",
    "\n",
    "question = \"What is dark matter?\"\n",
    "context = format_docs(retriever.invoke(question))\n",
    "\n",
    "prompt_template.format(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": f\"\"\"You are an astrophysics expert. Please answer the question on astrophysics based on the following context:\n",
    "\n",
    "            Context: {context}\n",
    "            \n",
    "            Question: {question}\"\"\"\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "23dc552e-c751-4c17-8fb6-4245c675e973",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|endoftext|>\\n\\n<|user|>\\nYou are an astrophysics expert. Please answer the question on astrophysics based on the following context:\\n\\n            Context: .. _astropy-coordinates-transforming:\\n\\nTransforming between Systems\\n****************************\\n\\n`astropy.coordinates` supports a rich system for transforming\\ncoordinates from one frame to another. While common astronomy frames\\nare built into Astropy, the transformation infrastructure is dynamic.\\nThis means it allows users to define new coordinate frames and their\\ntransformations. The topic of writing your own coordinate frame or\\ntransforms is detailed in :ref:`astropy-coordinates-design`, and this\\nsection is focused on how to *use* transformations.\\n\\nThe full list of built-in coordinate frames, the included transformations,\\nand the frame names are shown as a (clickable) graph in the\\n`~astropy.coordinates` API documentation.\\n\\nExamples\\n--------\\n\\n..\\n  EXAMPLE START\\n  Transforming Coordinates to Another Frame\\n\\nThe recommended method of transformation is shown below::\\n\\n    >>> import astropy.units as u\\n    >>> from astropy.coordinates import SkyCoord\\n    >>> gc = SkyCoord(l=0*u.degree, b=45*u.degree, frame=\\'galactic\\')\\n    >>> gc.fk5  # doctest: +FLOAT_CMP\\n    <SkyCoord (FK5: equinox=J2000.000): (ra, dec) in deg\\n        ( 229.27251463, -1.12844288)>\\n\\nWhile this appears to be ordinary attribute-style access, it is actually\\nsyntactic sugar for the more general\\n:meth:`~astropy.coordinates.SkyCoord.transform_to` method, which can\\naccept either a frame name, class, or instance::\\n\\n    >>> from astropy.coordinates import FK5\\n    >>> gc.transform_to(\\'fk5\\')  # doctest: +FLOAT_CMP\\n    <SkyCoord (FK5: equinox=J2000.000): (ra, dec) in deg\\n        ( 229.27251463, -1.12844288)>\\n    >>> gc.transform_to(FK5)  # doctest: +FLOAT_CMP\\n    <SkyCoord (FK5: equinox=J2000.000): (ra, dec) in deg\\n        ( 229.27251463, -1.12844288)>\\n    >>> gc.transform_to(FK5(equinox=\\'J1980.0\\'))  # doctest: +FLOAT_CMP\\n    <SkyCoord (FK5: equinox=J1980.000): (ra, dec) in deg\\n        ( 229.0146935, -1.05560349)>\\n\\n..\\n  EXAMPLE END\\n\\n..\\n  EXAMPLE START\\n  Using SkyCoord Objects as the Frame in Transformations\\n\\nAs a convenience, it is also possible to use a |SkyCoord| object as the frame in\\n:meth:`~astropy.coordinates.SkyCoord.transform_to`. This allows for putting one\\ncoordinate object into the frame of another::\\n\\n    >>> sc = SkyCoord(ra=1.0, dec=2.0, unit=\\'deg\\', frame=FK5, equinox=\\'J1980.0\\')\\n    >>> gc.transform_to(sc)  # doctest: +FLOAT_CMP\\n    <SkyCoord (FK5: equinox=J1980.000): (ra, dec) in deg\\n        ( 229.0146935, -1.05560349)>\\n\\n..\\n  EXAMPLE END\\n\\n..\\n  EXAMPLE START\\n  Self Transformations of Coordinate Frames\\n\\nSome coordinate frames (including `~astropy.coordinates.FK5`,\\n`~astropy.coordinates.FK4`, and `~astropy.coordinates.FK4NoETerms`) support\\n\"self transformations,\" meaning the *type* of frame does not change, but the\\nframe attributes do. An example is precessing a coordinate from one equinox\\nto another in an equatorial frame. This is done by passing ``transform_to`` a\\nframe class with the relevant attributes, as shown below. Note that these\\nframes use a default equinox if you do not specify one::\\n\\n    >>> fk5c = SkyCoord(\\'02h31m49.09s\\', \\'+89d15m50.8s\\', frame=FK5)\\n    >>> fk5c.equinox\\n    <Time object: scale=\\'tt\\' format=\\'jyear_str\\' value=J2000.000>\\n    >>> fk5c  # doctest: +FLOAT_CMP\\n    <SkyCoord (FK5: equinox=J2000.000): (ra, dec) in deg\\n        ( 37.95454167,  89.26411111)>\\n    >>> fk5_2005 = FK5(equinox=\\'J2005\\')  # String initializes an astropy.time.Time object\\n    >>> fk5c.transform_to(fk5_2005)  # doctest: +FLOAT_CMP\\n    <SkyCoord (FK5: equinox=J2005.000): (ra, dec) in deg\\n        ( 39.39317639,  89.28584422)>\\n\\nYou can also specify the equinox when you create a coordinate using a\\n`~astropy.time.Time` object::\\n\\n    >>> from astropy.time import Time\\n    >>> fk5c = SkyCoord(\\'02h31m49.09s\\', \\'+89d15m50.8s\\',\\n    ...                 frame=FK5(equinox=Time(\\'J1970\\')))\\n    >>> fk5_2000 = FK5(equinox=Time(2000, format=\\'jyear\\'))\\n    >>> fk5c.transform_to(fk5_2000)  # doctest: +FLOAT_CMP\\n    <SkyCoord (FK5: equinox=2000.0): (ra, dec) in deg\\n        ( 48.023171,  89.38672485)>\\n\\nThe same lower-level frame classes also have a\\n:meth:`~astropy.coordinates.BaseCoordinateFrame.transform_to` method\\nthat works the same as above, but they do not support attribute-style\\naccess. They are also subtly different in that they only use frame\\nattributes present in the initial or final frame, while |SkyCoord|\\nobjects use any frame attributes they have for all transformation\\nsteps. So |SkyCoord| can always transform from one frame to another and\\nback again without change, while low-level classes may lose information\\nand hence often do not round-trip.\\n\\n..\\n  EXAMPLE END\\n\\n.. _astropy-coordinates-transforming-ephemerides:\\n\\nTransformations and Solar System Ephemerides\\n============================================\\n\\nSome transformations (e.g., the transformation between\\n`~astropy.coordinates.ICRS` and `~astropy.coordinates.GCRS`) require the use of\\na Solar System ephemeris to calculate the position and velocity of the Earth\\nand Sun. By default, transformations are calculated using built-in\\n`ERFA <https://github.com/liberfa/erfa>`_ routines, but they can also use more\\nprecise ones using the JPL ephemerides (which are derived from dynamical\\nmodels).\\n\\nExample\\n-------\\n\\n..\\n  EXAMPLE START\\n  Calculating Transformations Using Solar System Ephemeris\\n\\nTo use the JPL ephemerides, use the\\n`~astropy.coordinates.solar_system_ephemeris` context manager, as shown below:\\n\\n.. doctest-requires:: jplephem\\n\\n    >>> from astropy.coordinates import solar_system_ephemeris\\n    >>> from astropy.coordinates import GCRS\\n    >>> with solar_system_ephemeris.set(\\'jpl\\'): # doctest: +REMOTE_DATA +IGNORE_OUTPUT\\n    ...     fk5c.transform_to(GCRS(obstime=Time(\"J2000\"))) # doctest: +REMOTE_DATA +IGNORE_OUTPUT\\n\\nFor locations at large distances from the Solar system, using the JPL\\nephemerides will make a negligible difference on the order of micro-arcseconds.\\nFor nearby objects, such as the Moon, the difference can be of the\\norder of milli-arcseconds. For more details about what ephemerides\\nare available, including the requirements for using JPL ephemerides, see\\n:ref:`astropy-coordinates-solarsystem`.\\n\\n..\\n  EXAMPLE END\\n\\n\\n  In Paper I, Greisen & Calabretta (2002) describe a generalized method for\\nassigning physical coordinates to FITS image pixels. This paper implements this\\nmethod for all spherical map projections likely to be of interest in astronomy.\\nThe new methods encompass existing informal FITS spherical coordinate\\nconventions and translations from them are described. Detailed examples of\\nheader interpretation and construction are given.\\n\\n            \\n            Question: How can I perform celestial coordinate transformations?\\n\\n\\n<|assistant|>\\n\\n'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the prompt you want to send to OLMo.\n",
    "question = \"How can I perform celestial coordinate transformations?\"\n",
    "context = format_docs(retriever.invoke(question))\n",
    "\n",
    "prompt_template.format(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": f\"\"\"You are an astrophysics expert. Please answer the question on astrophysics based on the following context:\n",
    "\n",
    "            Context: {context}\n",
    "            \n",
    "            Question: {question}\"\"\"\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15c270d-60fc-4b84-be3d-f9897a189dba",
   "metadata": {},
   "source": [
    "One way to generate the response with OLMo is to build `context` using the `question` beforehand, as shown above, create an llm_chain then `invoke` it with `messages`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5e4f5393-e92f-44ee-8a29-46f5d5a5b308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain the prompt template and olmo\n",
    "llm_chain = prompt_template | olmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e524031d-d379-46c9-b177-086e6a4d7162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dark matter is a theoretical particle that is believed to make up most of the matter in the universe, but does not emit any light or radiation, making it invisible to our current technology. This mysterious substance was discovered through its gravitational effects on visible matter such as stars, galaxies, and the large-scale structure of the universe. Since it does not interact with light, dark matter is often referred to as \"non-baryonic\" because it does not contain any baryonic matter (i.e., ordinary atoms).\n",
      "\n",
      "The exact nature of dark matter remains unknown, but based on current observations and theoretical models, it is believed that dark matter particles likely do not have charges or spin, and are stable, meaning they have not decayed into visible matter yet. Some possibilities for what dark matter may be include weakly interacting massive particles (WIMPs) such as neutralinos, axion-like particles (ALPs), or other unknown particles that could interact via gravity only.\n",
      "\n",
      "In the context of this research paper, the Galactic Centre is an ideal target for indirect searches for dark matter because it contains a higher density of dark matter compared to most parts of the Milky Way. Indirect searches aim to detect signals from dark matter interactions, such as annihilations or decays, that could be detected by observatories like IceCube. By improving the sensitivities of these analyses, researchers can better understand the nature and properties of dark matter particles and their interaction with other matter in the universe."
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Dark matter is a theoretical particle that is believed to make up most of the matter in the universe, but does not emit any light or radiation, making it invisible to our current technology. This mysterious substance was discovered through its gravitational effects on visible matter such as stars, galaxies, and the large-scale structure of the universe. Since it does not interact with light, dark matter is often referred to as \"non-baryonic\" because it does not contain any baryonic matter (i.e., ordinary atoms).\\n\\nThe exact nature of dark matter remains unknown, but based on current observations and theoretical models, it is believed that dark matter particles likely do not have charges or spin, and are stable, meaning they have not decayed into visible matter yet. Some possibilities for what dark matter may be include weakly interacting massive particles (WIMPs) such as neutralinos, axion-like particles (ALPs), or other unknown particles that could interact via gravity only.\\n\\nIn the context of this research paper, the Galactic Centre is an ideal target for indirect searches for dark matter because it contains a higher density of dark matter compared to most parts of the Milky Way. Indirect searches aim to detect signals from dark matter interactions, such as annihilations or decays, that could be detected by observatories like IceCube. By improving the sensitivities of these analyses, researchers can better understand the nature and properties of dark matter particles and their interaction with other matter in the universe.'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What is dark matter?\"\n",
    "context = format_docs(retriever.invoke(question))\n",
    "\n",
    "# Invoke the chain with a question and other parameters. \n",
    "llm_chain.invoke(\n",
    "    {\n",
    "        \"messages\":\n",
    "            [{\n",
    "                \"role\": \"user\", \n",
    "                \"content\": f\"\"\"You are an astrophysics expert. Please answer the question on astrophysics based on the following context:\n",
    "    \n",
    "                Context: {context}\n",
    "                \n",
    "                Question: {question}\"\"\"\n",
    "            }\n",
    "        ], \n",
    "    },\n",
    "    config={\n",
    "        'callbacks' : [StreamingStdOutCallbackHandler()]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b826474-9d60-4dfc-ad22-7012d1e90fd2",
   "metadata": {},
   "source": [
    "We can further use [LangChain's convenience functions](https://python.langchain.com/v0.2/docs/tutorials/rag/#built-in-chains) to streamline our pipeline using [create_stuff_documents_chain](https://api.python.langchain.com/en/latest/chains/langchain.chains.combine_documents.stuff.create_stuff_documents_chain.html) and [create_retrieval_chain](https://api.python.langchain.com/en/latest/chains/langchain.chains.retrieval.create_retrieval_chain.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cd3349-f0d0-4645-93af-533561ff3da6",
   "metadata": {},
   "source": [
    "`create_stuff_documents_chain` specifies how retrieved context is fed into a prompt and LLM. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30370bee-5e4f-49ef-976c-a1d18eb1064e",
   "metadata": {},
   "source": [
    "On looking its signature, notice that it accepts `prompt` argument of type `BasePromptTemplate` but it needs input keys as `context` and `input`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7e9f2d4b-311f-49cd-b8f2-acb115beee0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment below line and run the cell\n",
    "#create_stuff_documents_chain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8af92304-e15d-407f-bcdb-ea797fe4db31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['context', 'input'], template='<|endoftext|>\\n\\n<|user|>\\nYou are an astrophysics expert. Please answer the question on astrophysics based on the following context.                             Context: {context}                             Question: {input}\\n\\n\\n<|assistant|>\\n\\n')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is how we can tranform our prompt_template, so that it accepts `context` and `input` as input_variables\n",
    "transformed_prompt_template = PromptTemplate.from_template(\n",
    "    prompt_template.partial(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\", \n",
    "                \"content\": \"You are an astrophysics expert. Please answer the question on astrophysics based on the following context. \\\n",
    "                            Context: {context} \\\n",
    "                            Question: {input}\"\n",
    "            }\n",
    "        ]\n",
    "    ).format()\n",
    ")\n",
    "transformed_prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f30853bb-6b4f-44a2-9a72-78748a7d290c",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_chain = create_stuff_documents_chain(\n",
    "    llm=olmo, \n",
    "    prompt=transformed_prompt_template\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e24ea7e-6020-4573-9a6d-45309b04f521",
   "metadata": {},
   "source": [
    "We can run this by passing in the context directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "96cb5068-871a-4699-b765-6a8a4d4a4ed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dark matter is a theoretical phenomenon that explains the observed gravitational effects in the universe, which cannot be attributed to the presence of visible or ordinary matter. In the context provided, dark matter refers to non-baryonic matter particles that do not emit, absorb or reflect any electromagnetic radiation and are therefore invisible to us. The term \"dark\" does not refer to its color but rather to its lack of visibility due to this absence of electromagnetic radiation.\\n\\nDark matter is believed to make up approximately 85% of the total matter content in the universe (excluding ordinary particles that are composed of quarks and leptons). It has a significant impact on the cosmic structure, including the formation and evolution of galaxies, stars, and star systems. However, direct evidence for dark matter particles remains elusive due to their weak interactions with other types of matter.\\n\\nThe existence of dark matter is based on various observational indications from astrophysics and cosmology that suggest the need for a new form of matter to explain these observations. While it\\'s still unclear about the properties and composition of dark matter, it has been suggested that Weakly Interacting Massive Particles (WIMPs) are most likely candidates.\\n\\nThe Milky Way is expected to be permeated by a dark matter halo with an increased density towards its center. IceCube is an experiment designed to search for high-energy neutrinos, which could arise from the annihilations or decays of dark matter particles in the Galactic Center as part of indirect searches for dark matter. In this contribution, improvements have been made to the sensitivity of such searches by focusing on a lower energy range (5 GeV to 1 TeV).'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What is dark matter?\"\n",
    "document_chain.invoke({\n",
    "    \"input\": question,\n",
    "    \"context\": retriever.invoke(question),\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf29c92-7dfd-402d-b13d-bb868e3305ce",
   "metadata": {},
   "source": [
    "However, we want the context to be dynamically generated using the passed input or question."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37704b84-0dd4-4580-83f8-9a22f4572f0d",
   "metadata": {},
   "source": [
    "From LangChain's documentation: `create_retrieval_chain` adds the retrieval step and propagates the retrieved context through the chain, providing it alongside the final answer. It has input key `input`, and includes input, context, and answer in its output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "08fc17be-fbc6-4cf5-9a10-56b95ff0a666",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "65b13284-0f97-4d61-af71-d1b80ab78266",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = retrieval_chain.invoke({\"input\": \"What is dark matter?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7fef151e-fa29-437f-8051-160b3da2baba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'What is dark matter?',\n",
       " 'context': [Document(page_content='  I give a review of the development of the concept of dark matter. The dark\\nmatter story passed through several stages from a minor observational puzzle to\\na major challenge for theory of elementary particles. Modern data suggest that\\ndark matter is the dominant matter component in the Universe, and that it\\nconsists of some unknown non-baryonic particles. Properties of dark matter\\nparticles determine the structure of the cosmic web.\\n', metadata={'id': 1109.558, 'title': 'Dark matter', '_id': '363091ccc8f643fa9b51eed9aa157ad9', '_collection_name': 'arxiv_astro-ph_abstracts_astropy_github_documentation'}),\n",
       "  Document(page_content='  Even though there are strong astrophysical and cosmological indications to\\nsupport the existence of dark matter, its exact nature remains unknown. We\\nexpect dark matter to produce standard model particles when annihilating or\\ndecaying, assuming that it is composed of Weakly Interacting Massive Particles\\n(WIMPs). These standard model particles could in turn yield neutrinos that can\\nbe detected by the IceCube neutrino telescope. The Milky Way is expected to be\\npermeated by a dark matter halo with an increased density towards its centre.\\nThis halo is expected to yield the strongest dark matter annihilation signal at\\nEarth coming from any celestial object, making it an ideal target for indirect\\nsearches. In this contribution, we present the sensitivities of an indirect\\nsearch for dark matter in the Galactic Centre using IceCube data. This low\\nenergy dark matter search allows us to cover dark matter masses ranging from 5\\nGeV to 1 TeV. The sensitivities obtained for this analysis show considerable\\nimprovements over previous IceCube results in the considered energy range.\\n', metadata={'id': 2107.11224, 'title': 'Indirect search for dark matter in the Galactic Centre with IceCube', '_id': '54e8d56798d04046b498f599970cdb79', '_collection_name': 'arxiv_astro-ph_abstracts_astropy_github_documentation'})],\n",
       " 'answer': ' Dark matter is a theoretical concept in astrophysics and cosmology that describes the existence of a form of matter that cannot be seen or detected directly, but still has an effect on the observable universe. This mysterious substance accounts for approximately 85% of the total mass-energy content of the universe, and its absence from visible light is known as \"dark\" matter.\\n\\nDark matter particles are assumed to have weakly interacting massive particles (WIMPs), which means that they interact very weakly with other subatomic particles or even light itself. These properties allow dark matter to be a significant component of our cosmic neighborhood without being easily detected by any direct observation method. The exact nature and properties of dark matter remain unknown, making it an intriguing and active field of research in astrophysics and particle physics.\\n\\nIn this context, the Milky Way is expected to be permeated with a dark matter halo that has a higher density towards its center, which makes it an ideal target for indirect searches, as the presence of dark matter in the Galactic Centre can yield a stronger annihilation signal when compared to other celestial objects. The IceCube neutrino telescope provides the opportunity to search for low-energy (5 GeV - 1 TeV) dark matter signals.\\n\\nIceCube\\'s low energy dark matter search has significantly improved sensitivities over previous IceCube results, which is important in the quest to understand the nature and properties of this mysterious substance that plays a crucial role in our cosmic neighborhood.'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "abea391c-1ce8-49cb-96d2-e5d8e7fb628b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dark matter is a theoretical concept in astrophysics and cosmology that describes the existence of a form of matter that cannot be seen or detected directly, but still has an effect on the observable universe. This mysterious substance accounts for approximately 85% of the total mass-energy content of the universe, and its absence from visible light is known as \"dark\" matter.\n",
      "\n",
      "Dark matter particles are assumed to have weakly interacting massive particles (WIMPs), which means that they interact very weakly with other subatomic particles or even light itself. These properties allow dark matter to be a significant component of our cosmic neighborhood without being easily detected by any direct observation method. The exact nature and properties of dark matter remain unknown, making it an intriguing and active field of research in astrophysics and particle physics.\n",
      "\n",
      "In this context, the Milky Way is expected to be permeated with a dark matter halo that has a higher density towards its center, which makes it an ideal target for indirect searches, as the presence of dark matter in the Galactic Centre can yield a stronger annihilation signal when compared to other celestial objects. The IceCube neutrino telescope provides the opportunity to search for low-energy (5 GeV - 1 TeV) dark matter signals.\n",
      "\n",
      "IceCube's low energy dark matter search has significantly improved sensitivities over previous IceCube results, which is important in the quest to understand the nature and properties of this mysterious substance that plays a crucial role in our cosmic neighborhood.\n"
     ]
    }
   ],
   "source": [
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "76564c1c-afcf-485d-bb6b-a635c289a8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The provided context discusses the detailed abundance analysis of 140 stars using the method presented by Erspamer and North (2002). The study reveals a correlation between [Fe/H] and logg for stars within 1.8 to 2.0 Mo, but does not find an anticorrelation between vsini and elemental abundances as suggested in Varenne and Monier (1999).\n",
      "\n",
      "To answer your question, the number of dimensions in the elemental abundances of stars is two - the spatial dimension represented by the location of the star in the solar neighbourhood, and the radial velocity dimension, which is also two-dimensional. In this context, \"dimensions\" refers to the number of independent variables being considered.\n"
     ]
    }
   ],
   "source": [
    "response = retrieval_chain.invoke({\"input\": \"How many dimensions are there in the elemental abundances of stars?\"})\n",
    "print(response[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
