{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Retrieval-Augmented Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import langchain\n",
    "import textwrap\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain_community.llms import LlamaCpp\n",
    "from langchain_core.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_qdrant import Qdrant\n",
    "from langchain_huggingface import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cpp import Llama\n",
    "from scipy import spatial\n",
    "from qdrant_client import QdrantClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ssec_tutorials import (\n",
    "    OLMO_MODEL,\n",
    "    QDRANT_PATH,\n",
    "    QDRANT_COLLECTION_NAME,\n",
    "    download_qdrant_data,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "Although trained on large datasets, stale data can severely limit LLMs. It faces several challenges:\n",
    "\n",
    "1. The models are trained on internet content, so they might not generate relevant output when prompted for information that is not publicly available on the internet.\n",
    "\n",
    "2. The models are trained up to a certain date, they might not generate relevant output when prompted for content and information that has happened after the training completion date of the model.\n",
    "\n",
    "3. The models are trained to be more generalized. This means that they can only produce generic outputs and might not perform as expected when prompted for specific deep-dive concepts related to a particular topic.\n",
    "\n",
    "One way to dynamically integrate relevant external information is retrieval-augmented generation (RAG), which can help improve the reliability of LLM outputs. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## RAG Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "RAG proposes a solution to this issue by supplementing the prompt sent to the LLM with information from external sources through a retrieval model, thereby providing the LLM with more relevant input to generation responses. It allows you to use pre-trained LLMs without fine-tuning them or training your own LLM on your training data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "![RAG Workflow](../../images/rag-workflow.webp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "\n",
    "Image Source: [Medium Blog](https://medium.com/@henryhengluo/intro-of-retrieval-augmented-generation-rag-and-application-demos-c1d9239ababf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "Multiple concepts influence RAG pipeline:\n",
    "\n",
    "1. Retrieval\n",
    "2. Augmentation\n",
    "3. Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Retrieval\n",
    "\n",
    "The retrieval phase can also be considered the data and query/prompt preparation phase, focusing on efficient information retrieval or data access. To improve your RAG pipeline, the pre-retrieval phase contains tasks such as: `(1): Indexing, (2) Query Manipulation, (3) Data Modification, (4) Search, and (5) Ranking.` In this tutorial, we primarily focus on indexing and search. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "`Indexing` enables fast and accurate information retrieval that sets up the context for any LLM to improve its response to a given user prompt or query. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "We will be indexing abstracts for all astrophysics papers and Astropy's documentation, a common core package for Astronomy in Python. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "Embeddings, also called \"Vector Embedding,\" help LLMs develop a semantic understanding of the textual data they are trained on. In simpler terms, these embedding models lay the groundwork for LLMs to perform tasks like sentence completion, similarity search, questions and answers, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "#### Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "At the lowest level, machines only understand numeric values. For LLMs to work, natural language is converted into an array of numeric values before they are fed into the models. These arrays of numeric values are called \"Vector.\"\n",
    "\n",
    "An example of a vector: [2.5, 1.0, 3.3, 7.8]\n",
    "\n",
    "The above is an example of a vector of size 4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector: [2.5 1.7 3.3 7.8]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "vector = np.array([2.5, 1.7, 3.3, 7.8])\n",
    "print(f\"Vector: {vector}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "#### Tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "We stated above that **\"texts are converted into an array of numeric values called vectors\"**.\n",
    "\n",
    "But depending on your use case, each word, sentence, paragraph, or entire document can be represented as a vector. \n",
    "\n",
    "Tokens are the smallest natural language units converted into a vector. It could be at the character level, sub-word level, word level, sentence level, paragraph level, or document level.\n",
    "\n",
    "Example: Consider the text below.\n",
    "\n",
    "`Earth is a planet of the solar system. There are 9 planets in the solar system. \n",
    "All planets revolve around the sun. Sun is a star.`\n",
    "\n",
    "\n",
    "Case 1.) **Tokenizing the entire paragraph into vector.**  \n",
    "Tokenization: The entire paragraph is a single token.   \n",
    "Vectorization: A single vector.  \n",
    "Sample Vector Representation: [3.1, 6.8, 5.4, 8.0, 7.1]\n",
    "\n",
    "Case 2.) **Tokenizing each sentence into vectors.**  \n",
    "Tokenization: One token for each sentence (total 4 tokens)  \n",
    "Vectorization: One vector for each sentence (total 4 vectors).   \n",
    "Sample Vector Representation: [[1.2, 2.3, 3.8, 7.9, 0.8], [2.5, 3.0, 8.2, 6.6, 4.1], [3.2, 6.5, 8.1, 9.3, 1.4], [1.1, 0.7, 7.2, 3.5, 8.5]]\n",
    "\n",
    "Case 3.) **Tokenizing each word in the paragraph into a vector. There are 26 words in the paragraph, ignoring punctuation. Each word gets converted into a vector.**  \n",
    "Tokenization: One token for each word in the paragraph (26 tokens)  \n",
    "Vectorization: One vector for each token (total 26 vectors).    \n",
    "Sample Vector Representation: [[2.1, 3.2, 4.1, 9.8, 7.0], [8.2, 4.2, 7.1, 3.8, 2.0].....total 26 such representations]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "#### Tokenizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "Tokenizers are components responsible for converting large texts into tokens (tokenization). Different types of pre-trained tokenizers are available. You can even train your own tokenizers. But for the scope of this tutorial, we will use a pre-trained one. \n",
    "\n",
    "Generally, each tokenizer follows the following steps:\n",
    "\n",
    "1. Break down the original text into tokens. These tokens could again be at the character, sub-word, word, sentence, paragraph, or document levels.\n",
    "2. Assign a unique identifier to each of the tokens created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For example, here is how you can split a short sentence into chunks of text\n",
    "from langchain_text_splitters import CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Earth is a', 'planet in', 'the solar', 'system.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\" \",\n",
    "    chunk_size=10,\n",
    "    chunk_overlap=0,\n",
    ")\n",
    "text_splitter.split_text(text=\"Earth is a planet in the solar system.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "[Learn more about how to split text into tokens in LangChain here.](https://python.langchain.com/v0.2/docs/how_to/split_by_token/) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "#### Embedding Models\n",
    "\n",
    "A language model needs to understand how tokens are related to each other in the context of human language. To understand this semantic relationship, these tokens are converted into numerical vectors.\n",
    "\n",
    "Embedding Models are trained upon these tokens to develop an \"embedding space.\"\n",
    "\n",
    "- Before the training, the embedding model initializes an N-dimensional 'vector' corresponding to each 'token' with random values. (Value of N depends on the embedding model)\n",
    "  \n",
    "- During the embedding model training, the values for these vectors are updated across iterations. In this process, similar or related tokens are updated to have similarly valued vectors.\n",
    "  \n",
    "- After the training, the collection of all the 'vectors' corresponding to all the tokens is called the \"embedding space.\"\n",
    "\n",
    "- \"Embedding Space\" is an encoded representation of meanings of tokens and inter-token relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "> We now embed our relevant documents (knowledge base) into a pre-trained embedding model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the embedding, we are using the MiniLM model here\n",
    "embeddings_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L12-v2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_result = embeddings_model.embed_query(\"Earth is a planet in the solar system.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dimension of vector\n",
    "len(query_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.05409970134496689, 0.07589352875947952, -0.04195248335599899]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_result[-3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "In an embedding space, you can find how similar two vectors are using `dot product` or  using `cosine similarity.`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.7926038246541188\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Similarity:\",\n",
    "    1\n",
    "    - spatial.distance.cosine(\n",
    "        query_result,\n",
    "        embeddings_model.embed_query(\"Mars is a planet in the solar system.\"),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.08770959442668558\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Similarity:\",\n",
    "    1\n",
    "    - spatial.distance.cosine(\n",
    "        query_result, embeddings_model.embed_query(\"Hello Tacoma.\")\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "#### Vector Stores\n",
    "\n",
    "Once the embeddings are created for our relevant documents or knowledge base, we need to store these embeddings in the database for fast retrieval. \n",
    "\n",
    "The type of databases that store these vector embeddings are called \"Vector Stores.\" We will use a vector store called \"Qdrant,\" as shown below. \n",
    "\n",
    "In the below code, \n",
    "- Vector store works along with the embedding model to create vector embeddings.\n",
    "- Vector embeddings are stored in the Qdrant Vector database collection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "We have already created a vector database that contains the astrophysics paper abstracts and Astropy's documentation, please refer to the notebook in the Appendix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qdrant data already exists at /Users/lsetiawan/.cache/ssec_tutorials/scipy_qdrant\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/lsetiawan/.cache/ssec_tutorials/scipy_qdrant')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download_qdrant_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/lsetiawan/.cache/ssec_tutorials/scipy_qdrant')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QDRANT_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arxiv_astro-ph_abstracts_astropy_github_documentation'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QDRANT_COLLECTION_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing Qdrant collection 'arxiv_astro-ph_abstracts_astropy_github_documentation'\n"
     ]
    }
   ],
   "source": [
    "# Setting up Qdrant\n",
    "if os.path.exists(QDRANT_PATH):\n",
    "    print(f\"Loading existing Qdrant collection '{QDRANT_COLLECTION_NAME}'\")\n",
    "\n",
    "    client = QdrantClient(path=QDRANT_PATH)\n",
    "\n",
    "    qdrant = Qdrant(\n",
    "        client=client,\n",
    "        collection_name=QDRANT_COLLECTION_NAME,\n",
    "        embeddings=embeddings_model,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "### Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the retriever for later step\n",
    "# mmr stands for  Maximum Marginal Relevance\n",
    "# \"MMR selects examples based on a combination of which examples are most similar to the inputs, while also optimizing for diversity. It does this by finding the examples with the embeddings that have the greatest cosine similarity with the inputs, and then iteratively adding them while penalizing them for closeness to already selected examples.\"\n",
    "retriever = qdrant.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='  One of the great scientific enigmas still unsolved, the existence of dark\\nmatter, is reviewed. Simple gravitational arguments imply that most of the mass\\nin the Universe, at least 90%, is some (unknown) non-luminous matter. Some\\nparticle candidates for dark matter are discussed with particular emphasis on\\nthe neutralino, a particle predicted by the supersymmetric extension of the\\nStandard Model of particle physics. Experiments searching for these relic\\nparticles, carried out by many groups around the world, are also discussed.\\nThese experiments are becoming more sensitive every year and in fact one of the\\ncollaborations claims that the first direct evidence for dark matter has\\nalready been observed.\\n', metadata={'id': 'hep-ph/0110122', 'title': 'The Enigma of the Dark Matter', '_id': '4ab99f7c922747d9a6a34b855d959779', '_collection_name': 'arxiv_astro-ph_abstracts_astropy_github_documentation'}),\n",
       " Document(page_content='  Dark matter could be composed of compact dark objects (CDOs). These objects\\nmay interact very weakly with normal matter and could move freely {\\\\it inside}\\nthe Earth. A CDO moving in the inner core of the Earth will have an orbital\\nperiod near 55 min and produce a time dependent signal in a gravimeter. Data\\nfrom superconducting gravimeters rule out such objects moving inside the Earth\\nunless their mass $m_D$ and or orbital radius $a$ are very small so that $m_D\\\\,\\na < 1.2\\\\times 10^{-13}M_\\\\oplus R_\\\\oplus$. Here $M_\\\\oplus$ and $R_\\\\oplus$ are\\nthe mass and radius of the Earth.\\n', metadata={'id': 1912.0094, 'title': 'Gravimeter search for compact dark matter objects moving in the Earth', '_id': '97fa0dcbd2aa45d28dfccaa150e724e2', '_collection_name': 'arxiv_astro-ph_abstracts_astropy_github_documentation'})]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"What is dark matter?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='.. _astropy-coordinates-transforming:\\n\\nTransforming between Systems\\n****************************\\n\\n`astropy.coordinates` supports a rich system for transforming\\ncoordinates from one frame to another. While common astronomy frames\\nare built into Astropy, the transformation infrastructure is dynamic.\\nThis means it allows users to define new coordinate frames and their\\ntransformations. The topic of writing your own coordinate frame or\\ntransforms is detailed in :ref:`astropy-coordinates-design`, and this\\nsection is focused on how to *use* transformations.\\n\\nThe full list of built-in coordinate frames, the included transformations,\\nand the frame names are shown as a (clickable) graph in the\\n`~astropy.coordinates` API documentation.\\n\\nExamples\\n--------\\n\\n..\\n  EXAMPLE START\\n  Transforming Coordinates to Another Frame\\n\\nThe recommended method of transformation is shown below::\\n\\n    >>> import astropy.units as u\\n    >>> from astropy.coordinates import SkyCoord\\n    >>> gc = SkyCoord(l=0*u.degree, b=45*u.degree, frame=\\'galactic\\')\\n    >>> gc.fk5  # doctest: +FLOAT_CMP\\n    <SkyCoord (FK5: equinox=J2000.000): (ra, dec) in deg\\n        ( 229.27251463, -1.12844288)>\\n\\nWhile this appears to be ordinary attribute-style access, it is actually\\nsyntactic sugar for the more general\\n:meth:`~astropy.coordinates.SkyCoord.transform_to` method, which can\\naccept either a frame name, class, or instance::\\n\\n    >>> from astropy.coordinates import FK5\\n    >>> gc.transform_to(\\'fk5\\')  # doctest: +FLOAT_CMP\\n    <SkyCoord (FK5: equinox=J2000.000): (ra, dec) in deg\\n        ( 229.27251463, -1.12844288)>\\n    >>> gc.transform_to(FK5)  # doctest: +FLOAT_CMP\\n    <SkyCoord (FK5: equinox=J2000.000): (ra, dec) in deg\\n        ( 229.27251463, -1.12844288)>\\n    >>> gc.transform_to(FK5(equinox=\\'J1980.0\\'))  # doctest: +FLOAT_CMP\\n    <SkyCoord (FK5: equinox=J1980.000): (ra, dec) in deg\\n        ( 229.0146935, -1.05560349)>\\n\\n..\\n  EXAMPLE END\\n\\n..\\n  EXAMPLE START\\n  Using SkyCoord Objects as the Frame in Transformations\\n\\nAs a convenience, it is also possible to use a |SkyCoord| object as the frame in\\n:meth:`~astropy.coordinates.SkyCoord.transform_to`. This allows for putting one\\ncoordinate object into the frame of another::\\n\\n    >>> sc = SkyCoord(ra=1.0, dec=2.0, unit=\\'deg\\', frame=FK5, equinox=\\'J1980.0\\')\\n    >>> gc.transform_to(sc)  # doctest: +FLOAT_CMP\\n    <SkyCoord (FK5: equinox=J1980.000): (ra, dec) in deg\\n        ( 229.0146935, -1.05560349)>\\n\\n..\\n  EXAMPLE END\\n\\n..\\n  EXAMPLE START\\n  Self Transformations of Coordinate Frames\\n\\nSome coordinate frames (including `~astropy.coordinates.FK5`,\\n`~astropy.coordinates.FK4`, and `~astropy.coordinates.FK4NoETerms`) support\\n\"self transformations,\" meaning the *type* of frame does not change, but the\\nframe attributes do. An example is precessing a coordinate from one equinox\\nto another in an equatorial frame. This is done by passing ``transform_to`` a\\nframe class with the relevant attributes, as shown below. Note that these\\nframes use a default equinox if you do not specify one::\\n\\n    >>> fk5c = SkyCoord(\\'02h31m49.09s\\', \\'+89d15m50.8s\\', frame=FK5)\\n    >>> fk5c.equinox\\n    <Time object: scale=\\'tt\\' format=\\'jyear_str\\' value=J2000.000>\\n    >>> fk5c  # doctest: +FLOAT_CMP\\n    <SkyCoord (FK5: equinox=J2000.000): (ra, dec) in deg\\n        ( 37.95454167,  89.26411111)>\\n    >>> fk5_2005 = FK5(equinox=\\'J2005\\')  # String initializes an astropy.time.Time object\\n    >>> fk5c.transform_to(fk5_2005)  # doctest: +FLOAT_CMP\\n    <SkyCoord (FK5: equinox=J2005.000): (ra, dec) in deg\\n        ( 39.39317639,  89.28584422)>\\n\\nYou can also specify the equinox when you create a coordinate using a\\n`~astropy.time.Time` object::\\n\\n    >>> from astropy.time import Time\\n    >>> fk5c = SkyCoord(\\'02h31m49.09s\\', \\'+89d15m50.8s\\',\\n    ...                 frame=FK5(equinox=Time(\\'J1970\\')))\\n    >>> fk5_2000 = FK5(equinox=Time(2000, format=\\'jyear\\'))\\n    >>> fk5c.transform_to(fk5_2000)  # doctest: +FLOAT_CMP\\n    <SkyCoord (FK5: equinox=2000.0): (ra, dec) in deg\\n        ( 48.023171,  89.38672485)>\\n\\nThe same lower-level frame classes also have a\\n:meth:`~astropy.coordinates.BaseCoordinateFrame.transform_to` method\\nthat works the same as above, but they do not support attribute-style\\naccess. They are also subtly different in that they only use frame\\nattributes present in the initial or final frame, while |SkyCoord|\\nobjects use any frame attributes they have for all transformation\\nsteps. So |SkyCoord| can always transform from one frame to another and\\nback again without change, while low-level classes may lose information\\nand hence often do not round-trip.\\n\\n..\\n  EXAMPLE END\\n\\n.. _astropy-coordinates-transforming-ephemerides:\\n\\nTransformations and Solar System Ephemerides\\n============================================\\n\\nSome transformations (e.g., the transformation between\\n`~astropy.coordinates.ICRS` and `~astropy.coordinates.GCRS`) require the use of\\na Solar System ephemeris to calculate the position and velocity of the Earth\\nand Sun. By default, transformations are calculated using built-in\\n`ERFA <https://github.com/liberfa/erfa>`_ routines, but they can also use more\\nprecise ones using the JPL ephemerides (which are derived from dynamical\\nmodels).\\n\\nExample\\n-------\\n\\n..\\n  EXAMPLE START\\n  Calculating Transformations Using Solar System Ephemeris\\n\\nTo use the JPL ephemerides, use the\\n`~astropy.coordinates.solar_system_ephemeris` context manager, as shown below:\\n\\n.. doctest-requires:: jplephem\\n\\n    >>> from astropy.coordinates import solar_system_ephemeris\\n    >>> from astropy.coordinates import GCRS\\n    >>> with solar_system_ephemeris.set(\\'jpl\\'): # doctest: +REMOTE_DATA +IGNORE_OUTPUT\\n    ...     fk5c.transform_to(GCRS(obstime=Time(\"J2000\"))) # doctest: +REMOTE_DATA +IGNORE_OUTPUT\\n\\nFor locations at large distances from the Solar system, using the JPL\\nephemerides will make a negligible difference on the order of micro-arcseconds.\\nFor nearby objects, such as the Moon, the difference can be of the\\norder of milli-arcseconds. For more details about what ephemerides\\nare available, including the requirements for using JPL ephemerides, see\\n:ref:`astropy-coordinates-solarsystem`.\\n\\n..\\n  EXAMPLE END\\n', metadata={'title': 'Transforming', 'url': 'https://raw.githubusercontent.com/astropy/astropy/main/docs/coordinates/transforming.rst', '_id': '7591267e1b4e423496b3a417848de92d', '_collection_name': 'arxiv_astro-ph_abstracts_astropy_github_documentation'}),\n",
       " Document(page_content=\"  Gorski et al (1999b) have earlier presented the outline of a\\npixelisation-to-spherical-coordinate transformation scheme which simultaneously\\nsatisfies three properties which are especially useful for rapid analyses of\\nmaps on a sphere: (i) equal spacing of pixels along lines of constant latitude,\\n(ii) equal pixel `areas' (solid angles) and (iii) hierarchical scaling with\\nincreasing numbers of pixels. Their outline is based on the division of the\\nsphere into twelve regions covering equal solid angles, which are\\nhierarchically subdivided in a way compatible with these three criteria. In\\nthis paper, a complete derivation of this scheme is presented, including, in\\nparticular, (1) the angle theta^* defining the limit between polar and\\nequatorial regions, and (2) the transformations from the unit interval [0,1]\\n\\\\wedge [0,1] to spherical coordinates in a polar region.\\n\", metadata={'id': 'astro-ph/0409533', 'title': 'A Solution to the Isolatitude, Equi-area, Hierarchical Pixel-Coordinate\\n  System', '_id': '98b95594b76a4e9eaa6f0d95c167d500', '_collection_name': 'arxiv_astro-ph_abstracts_astropy_github_documentation'})]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"How can I perform celestial coordinate transformations?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post-processing\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  One of the great scientific enigmas still unsolved, the existence of dark\n",
      "matter, is reviewed. Simple gravitational arguments imply that most of the mass\n",
      "in the Universe, at least 90%, is some (unknown) non-luminous matter. Some\n",
      "particle candidates for dark matter are discussed with particular emphasis on\n",
      "the neutralino, a particle predicted by the supersymmetric extension of the\n",
      "Standard Model of particle physics. Experiments searching for these relic\n",
      "particles, carried out by many groups around the world, are also discussed.\n",
      "These experiments are becoming more sensitive every year and in fact one of the\n",
      "collaborations claims that the first direct evidence for dark matter has\n",
      "already been observed.\n",
      "\n",
      "\n",
      "  Dark matter could be composed of compact dark objects (CDOs). These objects\n",
      "may interact very weakly with normal matter and could move freely {\\it inside}\n",
      "the Earth. A CDO moving in the inner core of the Earth will have an orbital\n",
      "period near 55 min and produce a time dependent signal in a gravimeter. Data\n",
      "from superconducting gravimeters rule out such objects moving inside the Earth\n",
      "unless their mass $m_D$ and or orbital radius $a$ are very small so that $m_D\\,\n",
      "a < 1.2\\times 10^{-13}M_\\oplus R_\\oplus$. Here $M_\\oplus$ and $R_\\oplus$ are\n",
      "the mass and radius of the Earth.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(format_docs(retriever.invoke(\"What is dark matter?\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _astropy-coordinates-transforming:\n",
      "\n",
      "Transforming between Systems\n",
      "****************************\n",
      "\n",
      "`astropy.coordinates` supports a rich system for transforming\n",
      "coordinates from one frame to another. While common astronomy frames\n",
      "are built into Astropy, the transformation infrastructure is dynamic.\n",
      "This means it allows users to define new coordinate frames and their\n",
      "transformations. The topic of writing your own coordinate frame or\n",
      "transforms is detailed in :ref:`astropy-coordinates-design`, and this\n",
      "section is focused on how to *use* transformations.\n",
      "\n",
      "The full list of built-in coordinate frames, the included transformations,\n",
      "and the frame names are shown as a (clickable) graph in the\n",
      "`~astropy.coordinates` API documentation.\n",
      "\n",
      "Examples\n",
      "--------\n",
      "\n",
      "..\n",
      "  EXAMPLE START\n",
      "  Transforming Coordinates to Another Frame\n",
      "\n",
      "The recommended method of transformation is shown below::\n",
      "\n",
      "    >>> import astropy.units as u\n",
      "    >>> from astropy.coordinates import SkyCoord\n",
      "    >>> gc = SkyCoord(l=0*u.degree, b=45*u.degree, frame='galactic')\n",
      "    >>> gc.fk5  # doctest: +FLOAT_CMP\n",
      "    <SkyCoord (FK5: equinox=J2000.000): (ra, dec) in deg\n",
      "        ( 229.27251463, -1.12844288)>\n",
      "\n",
      "While this appears to be ordinary attribute-style access, it is actually\n",
      "syntactic sugar for the more general\n",
      ":meth:`~astropy.coordinates.SkyCoord.transform_to` method, which can\n",
      "accept either a frame name, class, or instance::\n",
      "\n",
      "    >>> from astropy.coordinates import FK5\n",
      "    >>> gc.transform_to('fk5')  # doctest: +FLOAT_CMP\n",
      "    <SkyCoord (FK5: equinox=J2000.000): (ra, dec) in deg\n",
      "        ( 229.27251463, -1.12844288)>\n",
      "    >>> gc.transform_to(FK5)  # doctest: +FLOAT_CMP\n",
      "    <SkyCoord (FK5: equinox=J2000.000): (ra, dec) in deg\n",
      "        ( 229.27251463, -1.12844288)>\n",
      "    >>> gc.transform_to(FK5(equinox='J1980.0'))  # doctest: +FLOAT_CMP\n",
      "    <SkyCoord (FK5: equinox=J1980.000): (ra, dec) in deg\n",
      "        ( 229.0146935, -1.05560349)>\n",
      "\n",
      "..\n",
      "  EXAMPLE END\n",
      "\n",
      "..\n",
      "  EXAMPLE START\n",
      "  Using SkyCoord Objects as the Frame in Transformations\n",
      "\n",
      "As a convenience, it is also possible to use a |SkyCoord| object as the frame in\n",
      ":meth:`~astropy.coordinates.SkyCoord.transform_to`. This allows for putting one\n",
      "coordinate object into the frame of another::\n",
      "\n",
      "    >>> sc = SkyCoord(ra=1.0, dec=2.0, unit='deg', frame=FK5, equinox='J1980.0')\n",
      "    >>> gc.transform_to(sc)  # doctest: +FLOAT_CMP\n",
      "    <SkyCoord (FK5: equinox=J1980.000): (ra, dec) in deg\n",
      "        ( 229.0146935, -1.05560349)>\n",
      "\n",
      "..\n",
      "  EXAMPLE END\n",
      "\n",
      "..\n",
      "  EXAMPLE START\n",
      "  Self Transformations of Coordinate Frames\n",
      "\n",
      "Some coordinate frames (including `~astropy.coordinates.FK5`,\n",
      "`~astropy.coordinates.FK4`, and `~astropy.coordinates.FK4NoETerms`) support\n",
      "\"self transformations,\" meaning the *type* of frame does not change, but the\n",
      "frame attributes do. An example is precessing a coordinate from one equinox\n",
      "to another in an equatorial frame. This is done by passing ``transform_to`` a\n",
      "frame class with the relevant attributes, as shown below. Note that these\n",
      "frames use a default equinox if you do not specify one::\n",
      "\n",
      "    >>> fk5c = SkyCoord('02h31m49.09s', '+89d15m50.8s', frame=FK5)\n",
      "    >>> fk5c.equinox\n",
      "    <Time object: scale='tt' format='jyear_str' value=J2000.000>\n",
      "    >>> fk5c  # doctest: +FLOAT_CMP\n",
      "    <SkyCoord (FK5: equinox=J2000.000): (ra, dec) in deg\n",
      "        ( 37.95454167,  89.26411111)>\n",
      "    >>> fk5_2005 = FK5(equinox='J2005')  # String initializes an astropy.time.Time object\n",
      "    >>> fk5c.transform_to(fk5_2005)  # doctest: +FLOAT_CMP\n",
      "    <SkyCoord (FK5: equinox=J2005.000): (ra, dec) in deg\n",
      "        ( 39.39317639,  89.28584422)>\n",
      "\n",
      "You can also specify the equinox when you create a coordinate using a\n",
      "`~astropy.time.Time` object::\n",
      "\n",
      "    >>> from astropy.time import Time\n",
      "    >>> fk5c = SkyCoord('02h31m49.09s', '+89d15m50.8s',\n",
      "    ...                 frame=FK5(equinox=Time('J1970')))\n",
      "    >>> fk5_2000 = FK5(equinox=Time(2000, format='jyear'))\n",
      "    >>> fk5c.transform_to(fk5_2000)  # doctest: +FLOAT_CMP\n",
      "    <SkyCoord (FK5: equinox=2000.0): (ra, dec) in deg\n",
      "        ( 48.023171,  89.38672485)>\n",
      "\n",
      "The same lower-level frame classes also have a\n",
      ":meth:`~astropy.coordinates.BaseCoordinateFrame.transform_to` method\n",
      "that works the same as above, but they do not support attribute-style\n",
      "access. They are also subtly different in that they only use frame\n",
      "attributes present in the initial or final frame, while |SkyCoord|\n",
      "objects use any frame attributes they have for all transformation\n",
      "steps. So |SkyCoord| can always transform from one frame to another and\n",
      "back again without change, while low-level classes may lose information\n",
      "and hence often do not round-trip.\n",
      "\n",
      "..\n",
      "  EXAMPLE END\n",
      "\n",
      ".. _astropy-coordinates-transforming-ephemerides:\n",
      "\n",
      "Transformations and Solar System Ephemerides\n",
      "============================================\n",
      "\n",
      "Some transformations (e.g., the transformation between\n",
      "`~astropy.coordinates.ICRS` and `~astropy.coordinates.GCRS`) require the use of\n",
      "a Solar System ephemeris to calculate the position and velocity of the Earth\n",
      "and Sun. By default, transformations are calculated using built-in\n",
      "`ERFA <https://github.com/liberfa/erfa>`_ routines, but they can also use more\n",
      "precise ones using the JPL ephemerides (which are derived from dynamical\n",
      "models).\n",
      "\n",
      "Example\n",
      "-------\n",
      "\n",
      "..\n",
      "  EXAMPLE START\n",
      "  Calculating Transformations Using Solar System Ephemeris\n",
      "\n",
      "To use the JPL ephemerides, use the\n",
      "`~astropy.coordinates.solar_system_ephemeris` context manager, as shown below:\n",
      "\n",
      ".. doctest-requires:: jplephem\n",
      "\n",
      "    >>> from astropy.coordinates import solar_system_ephemeris\n",
      "    >>> from astropy.coordinates import GCRS\n",
      "    >>> with solar_system_ephemeris.set('jpl'): # doctest: +REMOTE_DATA +IGNORE_OUTPUT\n",
      "    ...     fk5c.transform_to(GCRS(obstime=Time(\"J2000\"))) # doctest: +REMOTE_DATA +IGNORE_OUTPUT\n",
      "\n",
      "For locations at large distances from the Solar system, using the JPL\n",
      "ephemerides will make a negligible difference on the order of micro-arcseconds.\n",
      "For nearby objects, such as the Moon, the difference can be of the\n",
      "order of milli-arcseconds. For more details about what ephemerides\n",
      "are available, including the requirements for using JPL ephemerides, see\n",
      ":ref:`astropy-coordinates-solarsystem`.\n",
      "\n",
      "..\n",
      "  EXAMPLE END\n",
      "\n",
      "\n",
      "  Gorski et al (1999b) have earlier presented the outline of a\n",
      "pixelisation-to-spherical-coordinate transformation scheme which simultaneously\n",
      "satisfies three properties which are especially useful for rapid analyses of\n",
      "maps on a sphere: (i) equal spacing of pixels along lines of constant latitude,\n",
      "(ii) equal pixel `areas' (solid angles) and (iii) hierarchical scaling with\n",
      "increasing numbers of pixels. Their outline is based on the division of the\n",
      "sphere into twelve regions covering equal solid angles, which are\n",
      "hierarchically subdivided in a way compatible with these three criteria. In\n",
      "this paper, a complete derivation of this scheme is presented, including, in\n",
      "particular, (1) the angle theta^* defining the limit between polar and\n",
      "equatorial regions, and (2) the transformations from the unit interval [0,1]\n",
      "\\wedge [0,1] to spherical coordinates in a polar region.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    format_docs(\n",
    "        retriever.invoke(\"How can I perform celestial coordinate transformations?\")\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {},
   "source": [
    "## Augmentation & Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {},
   "source": [
    "Now that we can retrieve the most relevant document based on a question, we can use the retrieved document and send it along with the prompt to increase the context for the LLM.\n",
    "\n",
    "This can also be referred to as the `retrieval-augmented prompt.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "olmo = LlamaCpp(\n",
    "    model_path=str(OLMO_MODEL),\n",
    "    temperature=0.8,\n",
    "    verbose=False,\n",
    "    n_ctx=2048,\n",
    "    max_tokens=512,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a prompt template using OLMo's tokenizer chat template we saw in module 1.\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    template=olmo.client.metadata[\"tokenizer.chat_template\"],\n",
    "    template_format=\"jinja2\",\n",
    "    partial_variables={\"add_generation_prompt\": True, \"eos_token\": \"<|endoftext|>\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['messages'], partial_variables={'add_generation_prompt': True, 'eos_token': '<|endoftext|>'}, template=\"{{ eos_token }}{% for message in messages %}\\n{% if message['role'] == 'user' %}\\n{{ '<|user|>\\n' + message['content'] }}\\n{% elif message['role'] == 'assistant' %}\\n{{ '<|assistant|>\\n'  + message['content'] + eos_token }}\\n{% endif %}\\n{% if loop.last and add_generation_prompt %}\\n{{ '<|assistant|>' }}\\n{% endif %}\\n{% endfor %}\", template_format='jinja2')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|endoftext|>\\n\\n<|user|>\\nYou are an astrophysics expert. Please answer the question on astrophysics based on the following context:\\n\\n            Context:   One of the great scientific enigmas still unsolved, the existence of dark\\nmatter, is reviewed. Simple gravitational arguments imply that most of the mass\\nin the Universe, at least 90%, is some (unknown) non-luminous matter. Some\\nparticle candidates for dark matter are discussed with particular emphasis on\\nthe neutralino, a particle predicted by the supersymmetric extension of the\\nStandard Model of particle physics. Experiments searching for these relic\\nparticles, carried out by many groups around the world, are also discussed.\\nThese experiments are becoming more sensitive every year and in fact one of the\\ncollaborations claims that the first direct evidence for dark matter has\\nalready been observed.\\n\\n\\n  Dark matter could be composed of compact dark objects (CDOs). These objects\\nmay interact very weakly with normal matter and could move freely {\\\\it inside}\\nthe Earth. A CDO moving in the inner core of the Earth will have an orbital\\nperiod near 55 min and produce a time dependent signal in a gravimeter. Data\\nfrom superconducting gravimeters rule out such objects moving inside the Earth\\nunless their mass $m_D$ and or orbital radius $a$ are very small so that $m_D\\\\,\\na < 1.2\\\\times 10^{-13}M_\\\\oplus R_\\\\oplus$. Here $M_\\\\oplus$ and $R_\\\\oplus$ are\\nthe mass and radius of the Earth.\\n\\n            \\n            Question: What is dark matter?\\n\\n\\n<|assistant|>\\n\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the prompt you want to send to OLMo.\n",
    "\n",
    "question = \"What is dark matter?\"\n",
    "context = format_docs(retriever.invoke(question))\n",
    "\n",
    "prompt_template.format(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"You are an astrophysics expert. Please answer the question on astrophysics based on the following context:\n",
    "\n",
    "            Context: {context}\n",
    "            \n",
    "            Question: {question}\"\"\",\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|endoftext|>\\n\\n<|user|>\\nYou are an astrophysics expert. Please answer the question on astrophysics based on the following context:\\n\\n            Context: .. _astropy-coordinates-transforming:\\n\\nTransforming between Systems\\n****************************\\n\\n`astropy.coordinates` supports a rich system for transforming\\ncoordinates from one frame to another. While common astronomy frames\\nare built into Astropy, the transformation infrastructure is dynamic.\\nThis means it allows users to define new coordinate frames and their\\ntransformations. The topic of writing your own coordinate frame or\\ntransforms is detailed in :ref:`astropy-coordinates-design`, and this\\nsection is focused on how to *use* transformations.\\n\\nThe full list of built-in coordinate frames, the included transformations,\\nand the frame names are shown as a (clickable) graph in the\\n`~astropy.coordinates` API documentation.\\n\\nExamples\\n--------\\n\\n..\\n  EXAMPLE START\\n  Transforming Coordinates to Another Frame\\n\\nThe recommended method of transformation is shown below::\\n\\n    >>> import astropy.units as u\\n    >>> from astropy.coordinates import SkyCoord\\n    >>> gc = SkyCoord(l=0*u.degree, b=45*u.degree, frame=\\'galactic\\')\\n    >>> gc.fk5  # doctest: +FLOAT_CMP\\n    <SkyCoord (FK5: equinox=J2000.000): (ra, dec) in deg\\n        ( 229.27251463, -1.12844288)>\\n\\nWhile this appears to be ordinary attribute-style access, it is actually\\nsyntactic sugar for the more general\\n:meth:`~astropy.coordinates.SkyCoord.transform_to` method, which can\\naccept either a frame name, class, or instance::\\n\\n    >>> from astropy.coordinates import FK5\\n    >>> gc.transform_to(\\'fk5\\')  # doctest: +FLOAT_CMP\\n    <SkyCoord (FK5: equinox=J2000.000): (ra, dec) in deg\\n        ( 229.27251463, -1.12844288)>\\n    >>> gc.transform_to(FK5)  # doctest: +FLOAT_CMP\\n    <SkyCoord (FK5: equinox=J2000.000): (ra, dec) in deg\\n        ( 229.27251463, -1.12844288)>\\n    >>> gc.transform_to(FK5(equinox=\\'J1980.0\\'))  # doctest: +FLOAT_CMP\\n    <SkyCoord (FK5: equinox=J1980.000): (ra, dec) in deg\\n        ( 229.0146935, -1.05560349)>\\n\\n..\\n  EXAMPLE END\\n\\n..\\n  EXAMPLE START\\n  Using SkyCoord Objects as the Frame in Transformations\\n\\nAs a convenience, it is also possible to use a |SkyCoord| object as the frame in\\n:meth:`~astropy.coordinates.SkyCoord.transform_to`. This allows for putting one\\ncoordinate object into the frame of another::\\n\\n    >>> sc = SkyCoord(ra=1.0, dec=2.0, unit=\\'deg\\', frame=FK5, equinox=\\'J1980.0\\')\\n    >>> gc.transform_to(sc)  # doctest: +FLOAT_CMP\\n    <SkyCoord (FK5: equinox=J1980.000): (ra, dec) in deg\\n        ( 229.0146935, -1.05560349)>\\n\\n..\\n  EXAMPLE END\\n\\n..\\n  EXAMPLE START\\n  Self Transformations of Coordinate Frames\\n\\nSome coordinate frames (including `~astropy.coordinates.FK5`,\\n`~astropy.coordinates.FK4`, and `~astropy.coordinates.FK4NoETerms`) support\\n\"self transformations,\" meaning the *type* of frame does not change, but the\\nframe attributes do. An example is precessing a coordinate from one equinox\\nto another in an equatorial frame. This is done by passing ``transform_to`` a\\nframe class with the relevant attributes, as shown below. Note that these\\nframes use a default equinox if you do not specify one::\\n\\n    >>> fk5c = SkyCoord(\\'02h31m49.09s\\', \\'+89d15m50.8s\\', frame=FK5)\\n    >>> fk5c.equinox\\n    <Time object: scale=\\'tt\\' format=\\'jyear_str\\' value=J2000.000>\\n    >>> fk5c  # doctest: +FLOAT_CMP\\n    <SkyCoord (FK5: equinox=J2000.000): (ra, dec) in deg\\n        ( 37.95454167,  89.26411111)>\\n    >>> fk5_2005 = FK5(equinox=\\'J2005\\')  # String initializes an astropy.time.Time object\\n    >>> fk5c.transform_to(fk5_2005)  # doctest: +FLOAT_CMP\\n    <SkyCoord (FK5: equinox=J2005.000): (ra, dec) in deg\\n        ( 39.39317639,  89.28584422)>\\n\\nYou can also specify the equinox when you create a coordinate using a\\n`~astropy.time.Time` object::\\n\\n    >>> from astropy.time import Time\\n    >>> fk5c = SkyCoord(\\'02h31m49.09s\\', \\'+89d15m50.8s\\',\\n    ...                 frame=FK5(equinox=Time(\\'J1970\\')))\\n    >>> fk5_2000 = FK5(equinox=Time(2000, format=\\'jyear\\'))\\n    >>> fk5c.transform_to(fk5_2000)  # doctest: +FLOAT_CMP\\n    <SkyCoord (FK5: equinox=2000.0): (ra, dec) in deg\\n        ( 48.023171,  89.38672485)>\\n\\nThe same lower-level frame classes also have a\\n:meth:`~astropy.coordinates.BaseCoordinateFrame.transform_to` method\\nthat works the same as above, but they do not support attribute-style\\naccess. They are also subtly different in that they only use frame\\nattributes present in the initial or final frame, while |SkyCoord|\\nobjects use any frame attributes they have for all transformation\\nsteps. So |SkyCoord| can always transform from one frame to another and\\nback again without change, while low-level classes may lose information\\nand hence often do not round-trip.\\n\\n..\\n  EXAMPLE END\\n\\n.. _astropy-coordinates-transforming-ephemerides:\\n\\nTransformations and Solar System Ephemerides\\n============================================\\n\\nSome transformations (e.g., the transformation between\\n`~astropy.coordinates.ICRS` and `~astropy.coordinates.GCRS`) require the use of\\na Solar System ephemeris to calculate the position and velocity of the Earth\\nand Sun. By default, transformations are calculated using built-in\\n`ERFA <https://github.com/liberfa/erfa>`_ routines, but they can also use more\\nprecise ones using the JPL ephemerides (which are derived from dynamical\\nmodels).\\n\\nExample\\n-------\\n\\n..\\n  EXAMPLE START\\n  Calculating Transformations Using Solar System Ephemeris\\n\\nTo use the JPL ephemerides, use the\\n`~astropy.coordinates.solar_system_ephemeris` context manager, as shown below:\\n\\n.. doctest-requires:: jplephem\\n\\n    >>> from astropy.coordinates import solar_system_ephemeris\\n    >>> from astropy.coordinates import GCRS\\n    >>> with solar_system_ephemeris.set(\\'jpl\\'): # doctest: +REMOTE_DATA +IGNORE_OUTPUT\\n    ...     fk5c.transform_to(GCRS(obstime=Time(\"J2000\"))) # doctest: +REMOTE_DATA +IGNORE_OUTPUT\\n\\nFor locations at large distances from the Solar system, using the JPL\\nephemerides will make a negligible difference on the order of micro-arcseconds.\\nFor nearby objects, such as the Moon, the difference can be of the\\norder of milli-arcseconds. For more details about what ephemerides\\nare available, including the requirements for using JPL ephemerides, see\\n:ref:`astropy-coordinates-solarsystem`.\\n\\n..\\n  EXAMPLE END\\n\\n\\n  Gorski et al (1999b) have earlier presented the outline of a\\npixelisation-to-spherical-coordinate transformation scheme which simultaneously\\nsatisfies three properties which are especially useful for rapid analyses of\\nmaps on a sphere: (i) equal spacing of pixels along lines of constant latitude,\\n(ii) equal pixel `areas\\' (solid angles) and (iii) hierarchical scaling with\\nincreasing numbers of pixels. Their outline is based on the division of the\\nsphere into twelve regions covering equal solid angles, which are\\nhierarchically subdivided in a way compatible with these three criteria. In\\nthis paper, a complete derivation of this scheme is presented, including, in\\nparticular, (1) the angle theta^* defining the limit between polar and\\nequatorial regions, and (2) the transformations from the unit interval [0,1]\\n\\\\wedge [0,1] to spherical coordinates in a polar region.\\n\\n            \\n            Question: How can I perform celestial coordinate transformations?\\n\\n\\n<|assistant|>\\n\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the prompt you want to send to OLMo.\n",
    "question = \"How can I perform celestial coordinate transformations?\"\n",
    "context = format_docs(retriever.invoke(question))\n",
    "\n",
    "prompt_template.format(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"You are an astrophysics expert. Please answer the question on astrophysics based on the following context:\n",
    "\n",
    "            Context: {context}\n",
    "            \n",
    "            Question: {question}\"\"\",\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56",
   "metadata": {},
   "source": [
    "One way to generate the response with OLMo is to build `context` using the `question` beforehand, as shown above, create an llm_chain then `invoke` it with `messages`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain the prompt template and olmo\n",
    "llm_chain = prompt_template | olmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dark matter is a hypothetical type of matter that is not visible or readily detected through traditional means, such as light. However, its existence can still be inferred based on the gravitational effects it has on other objects in the Universe. Based on the given context, simple gravitational arguments suggest that about 90% of the mass content of the universe is dark matter.\n",
      "\n",
      "The particle candidates for dark matter include neutralinos, which are predicted by the supersymmetric extension of the Standard Model of particle physics. These particles have nearly zero electric charge and do not interact significantly with normal matter. Their small interaction strength makes them difficult to detect, but recent experiments suggest evidence of their existence.\n",
      "\n",
      "Since dark matter is non-luminous (it does not emit or reflect light), it has been challenging to observe directly. However, some indirect evidence suggests the presence of dark matter in our universe. For example, data from superconducting gravimeters show that objects moving inside the Earth should have extremely small mass and orbital radius, such as $m_D\\, a < 1.2\\times 10^{-13} M_\\oplus R_\\oplus$. This condition implies that any compact dark object (CDO) moving inside the Earth could not have a significant mass compared to its size.\n",
      "\n",
      "In summary, dark matter is an unseen form of matter in our universe that plays a significant role in its overall composition and gravitational effects. Its existence can be inferred through astronomical observations but remains unobserved directly due to its non-luminous nature."
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Dark matter is a hypothetical type of matter that is not visible or readily detected through traditional means, such as light. However, its existence can still be inferred based on the gravitational effects it has on other objects in the Universe. Based on the given context, simple gravitational arguments suggest that about 90% of the mass content of the universe is dark matter.\\n\\nThe particle candidates for dark matter include neutralinos, which are predicted by the supersymmetric extension of the Standard Model of particle physics. These particles have nearly zero electric charge and do not interact significantly with normal matter. Their small interaction strength makes them difficult to detect, but recent experiments suggest evidence of their existence.\\n\\nSince dark matter is non-luminous (it does not emit or reflect light), it has been challenging to observe directly. However, some indirect evidence suggests the presence of dark matter in our universe. For example, data from superconducting gravimeters show that objects moving inside the Earth should have extremely small mass and orbital radius, such as $m_D\\\\, a < 1.2\\\\times 10^{-13} M_\\\\oplus R_\\\\oplus$. This condition implies that any compact dark object (CDO) moving inside the Earth could not have a significant mass compared to its size.\\n\\nIn summary, dark matter is an unseen form of matter in our universe that plays a significant role in its overall composition and gravitational effects. Its existence can be inferred through astronomical observations but remains unobserved directly due to its non-luminous nature.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What is dark matter?\"\n",
    "context = format_docs(retriever.invoke(question))\n",
    "\n",
    "# Invoke the chain with a question and other parameters.\n",
    "llm_chain.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"\"\"You are an astrophysics expert. Please answer the question on astrophysics based on the following context:\n",
    "    \n",
    "                Context: {context}\n",
    "                \n",
    "                Question: {question}\"\"\",\n",
    "            }\n",
    "        ],\n",
    "    },\n",
    "    config={\"callbacks\": [StreamingStdOutCallbackHandler()]},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59",
   "metadata": {},
   "source": [
    "We can further use [LangChain's convenience functions](https://python.langchain.com/v0.2/docs/tutorials/rag/#built-in-chains) to streamline our pipeline using [create_stuff_documents_chain](https://api.python.langchain.com/en/latest/chains/langchain.chains.combine_documents.stuff.create_stuff_documents_chain.html) and [create_retrieval_chain](https://api.python.langchain.com/en/latest/chains/langchain.chains.retrieval.create_retrieval_chain.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60",
   "metadata": {},
   "source": [
    "`create_stuff_documents_chain` specifies how retrieved context is fed into a prompt and LLM. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61",
   "metadata": {},
   "source": [
    "On looking its signature, notice that it accepts `prompt` argument of type `BasePromptTemplate` but it needs input keys as `context` and `input`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment below line and run the cell\n",
    "# create_stuff_documents_chain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['context', 'input'], template='<|endoftext|>\\n\\n<|user|>\\nYou are an astrophysics expert. Please answer the question on astrophysics based on the following context.                             Context: {context}                             Question: {input}\\n\\n\\n<|assistant|>\\n\\n')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is how we can transform our prompt_template, so that it accepts `context` and `input` as input_variables\n",
    "transformed_prompt_template = PromptTemplate.from_template(\n",
    "    prompt_template.partial(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"You are an astrophysics expert. Please answer the question on astrophysics based on the following context. \\\n",
    "                            Context: {context} \\\n",
    "                            Question: {input}\",\n",
    "            }\n",
    "        ]\n",
    "    ).format()\n",
    ")\n",
    "transformed_prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_chain = create_stuff_documents_chain(\n",
    "    llm=olmo, prompt=transformed_prompt_template\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65",
   "metadata": {},
   "source": [
    "We can run this by passing in the context directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dark matter is a hypothetical form of matter that has yet to be directly observed, but its presence is implied by various observations in astronomy and cosmology. According to gravitational arguments, 90% of the mass of the universe appears to consist of this mysterious dark matter material.\\n\\nThe most plausible candidate for dark matter is the neutralino, which is a particle predicted by the supersymmetric extension of the Standard Model of particle physics. Experimental searches have been ongoing involving various collaborations and continue to become more sensitive every year.\\n\\nDark matter could potentially be composed of compact dark objects (CDOs). These CDOs could interact very weakly with normal matter and move freely inside Earth, such as in its inner core. The constraints on the properties of these CDOs are quite specific. For instance, a CDO moving inside the Earth would have an orbital period near 55 minutes and produce a time-dependent signal in a gravimeter. However, data from superconducting gravimeters rule out such objects moving inside the Earth unless their mass (m_D) and/or orbital radius (a) are very small - that is, m_D < 1.2 x 10^-13 M_\\\\* R_\\\\*.\\n\\nIn summary, dark matter remains an enigmatic concept in astrophysics, and its nature still awaits discovery.'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What is dark matter?\"\n",
    "document_chain.invoke(\n",
    "    {\n",
    "        \"input\": question,\n",
    "        \"context\": retriever.invoke(question),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67",
   "metadata": {},
   "source": [
    "However, we want the context to be dynamically generated using the passed input or question."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68",
   "metadata": {},
   "source": [
    "From LangChain's documentation: `create_retrieval_chain` adds the retrieval step and propagates the retrieved context through the chain, providing it alongside the final answer. It has input key `input`, and includes input, context, and answer in its output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = retrieval_chain.invoke({\"input\": \"What is dark matter?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'What is dark matter?',\n",
       " 'context': [Document(page_content='  One of the great scientific enigmas still unsolved, the existence of dark\\nmatter, is reviewed. Simple gravitational arguments imply that most of the mass\\nin the Universe, at least 90%, is some (unknown) non-luminous matter. Some\\nparticle candidates for dark matter are discussed with particular emphasis on\\nthe neutralino, a particle predicted by the supersymmetric extension of the\\nStandard Model of particle physics. Experiments searching for these relic\\nparticles, carried out by many groups around the world, are also discussed.\\nThese experiments are becoming more sensitive every year and in fact one of the\\ncollaborations claims that the first direct evidence for dark matter has\\nalready been observed.\\n', metadata={'id': 'hep-ph/0110122', 'title': 'The Enigma of the Dark Matter', '_id': '4ab99f7c922747d9a6a34b855d959779', '_collection_name': 'arxiv_astro-ph_abstracts_astropy_github_documentation'}),\n",
       "  Document(page_content='  Dark matter could be composed of compact dark objects (CDOs). These objects\\nmay interact very weakly with normal matter and could move freely {\\\\it inside}\\nthe Earth. A CDO moving in the inner core of the Earth will have an orbital\\nperiod near 55 min and produce a time dependent signal in a gravimeter. Data\\nfrom superconducting gravimeters rule out such objects moving inside the Earth\\nunless their mass $m_D$ and or orbital radius $a$ are very small so that $m_D\\\\,\\na < 1.2\\\\times 10^{-13}M_\\\\oplus R_\\\\oplus$. Here $M_\\\\oplus$ and $R_\\\\oplus$ are\\nthe mass and radius of the Earth.\\n', metadata={'id': 1912.0094, 'title': 'Gravimeter search for compact dark matter objects moving in the Earth', '_id': '97fa0dcbd2aa45d28dfccaa150e724e2', '_collection_name': 'arxiv_astro-ph_abstracts_astropy_github_documentation'})],\n",
       " 'answer': 'Dark matter is a theoretical particle or collection of particles that accounts for most of the mass in the universe, as suggested by gravitational arguments based on the lack of visible stars, gas, and other forms of ordinary matter (see the context provided). In the context of astrophysics, dark matter is an enigmatic and crucial concept because it cannot be detected directly through its effects on regular matter.\\n\\nThe most popular candidate for dark matter is the neutralino. The neutralino was predicted by the supersymmetric extension of the Standard Model of particle physics and could potentially interact with ordinary matter very weakly or not at all. As of now, experiments searching for these relic particles have become more sensitive every year, and one collaboration claims that the first direct evidence for dark matter has already been observed.\\n\\nHowever, it is important to note that the existence of dark matter remains a scientific enigma, and its composition, properties, and distribution in the universe remain unknown. Research into dark matter continues as scientists seek to understand its fundamental nature and potential role in various celestial phenomena, such as the motions of stars and galaxies within our galaxy (Milky Way) and beyond.\\n\\nTo summarize, dark matter refers to a hypothetical particle or collection of particles that is essential to the cosmic mass budget but remains undetected due to its weak interactions with ordinary matter.'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dark matter is a theoretical particle or collection of particles that accounts for most of the mass in the universe, as suggested by gravitational arguments based on the lack of visible stars, gas, and other forms of ordinary matter (see the context provided). In the context of astrophysics, dark matter is an enigmatic and crucial concept because it cannot be detected directly through its effects on regular matter.\n",
      "\n",
      "The most popular candidate for dark matter is the neutralino. The neutralino was predicted by the supersymmetric extension of the Standard Model of particle physics and could potentially interact with ordinary matter very weakly or not at all. As of now, experiments searching for these relic particles have become more sensitive every year, and one collaboration claims that the first direct evidence for dark matter has already been observed.\n",
      "\n",
      "However, it is important to note that the existence of dark matter remains a scientific enigma, and its composition, properties, and distribution in the universe remain unknown. Research into dark matter continues as scientists seek to understand its fundamental nature and potential role in various celestial phenomena, such as the motions of stars and galaxies within our galaxy (Milky Way) and beyond.\n",
      "\n",
      "To summarize, dark matter refers to a hypothetical particle or collection of particles that is essential to the cosmic mass budget but remains undetected due to its weak interactions with ordinary matter.\n"
     ]
    }
   ],
   "source": [
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Based on the context provided, the high-resolution spectroscopic elemental abundance survey mentioned focuses on F and G dwarf stars in the solar neighborhood. The study presents detailed abundances of 140 stars using the method presented by Erspamer and North (2002) with uncertainties discussed. The method is shown to be applicable for S/N ratios higher than 200 and up to rotational velocities of 200 km/s. The abundance differences between metallic giants (Hauck 1986) and normal giants are found for at least 8 elements: Al, Ca, Ti, Cr, Mn, Fe, Ni, and Ba. \n",
      "\n",
      "To answer the question, we can say that the elemental abundances of stars have 10 dimensions. This is because each star has one value for each element mentioned (Al, Ca, Ti, Cr, Mn, Fe, Ni, and Ba). Although other dimensions might be present in a more comprehensive analysis of stellar physics, these 10 dimensions are highlighted based on the given context.\n"
     ]
    }
   ],
   "source": [
    "response = retrieval_chain.invoke(\n",
    "    {\"input\": \"How many dimensions are there in the elemental abundances of stars?\"}\n",
    ")\n",
    "print(response[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
