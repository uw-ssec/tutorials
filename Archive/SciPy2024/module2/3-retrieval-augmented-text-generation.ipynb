{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Retrieval-Augmented Text Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c560a25",
   "metadata": {},
   "source": [
    "The moment that we've all been waiting for has finally arrived! The Retrieval-Augmented Text Generation (RAG) Framework is here! ðŸŽ‰\n",
    "\n",
    "Throughout this notebook we will be exploring RAG, what it is, how it works, and why it's so exciting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea1041c",
   "metadata": {},
   "source": [
    "## Why RAG?\n",
    "\n",
    "Although trained on large datasets, stale data can severely limit LLMs. It faces several challenges:\n",
    "\n",
    "1. The models are trained on internet content, so they might not generate relevant output when prompted for information that is not publicly available on the internet.\n",
    "\n",
    "2. The models are trained up to a certain date, they might not generate relevant output when prompted for content and information that has happened after the training completion date of the model.\n",
    "\n",
    "3. The models are trained to be more generalized. This means that they can only produce generic outputs and might not perform as expected when prompted for specific deep-dive concepts related to a particular topic.\n",
    "\n",
    "One way to dynamically integrate relevant external information is retrieval-augmented generation (RAG), which can help improve the reliability of LLM outputs.\n",
    "\n",
    "Going back to our original question of how this can be utilized in our own work or organization on [section 1](1-domain-specific-question-answering.ipynb) of this module. RAG Framework can really be useful in the scenario where there may be a set of documents, GitHub repositories, research papers, and domain-specific knowledge bases that you might want to search through quickly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## RAG Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "RAG proposes a solution to this issue by supplementing the prompt sent to the LLM with information from external sources through a retrieval model via vector embeddings (more on this later), thereby providing the LLM with more relevant input to generation responses. It allows you to use pre-trained LLMs without fine-tuning them or training your own LLM on your training data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "![RAG Workflow](../../images/rag-workflow.webp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "\n",
    "Image Source: [Medium Blog](https://medium.com/@henryhengluo/intro-of-retrieval-augmented-generation-rag-and-application-demos-c1d9239ababf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "Multiple concepts influence RAG pipeline:\n",
    "\n",
    "1. Retrieval\n",
    "2. Augmentation\n",
    "3. Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Retrieval\n",
    "\n",
    "The retrieval phase can also be considered the data and query/prompt preparation phase, focusing on efficient information retrieval or data access. To improve your RAG pipeline, the pre-retrieval phase contains tasks such as: `(1): Indexing, (2) Query Manipulation, (3) Data Modification, (4) Search, and (5) Ranking.` In this tutorial, we primarily focus on indexing and search. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "`Indexing` enables fast and accurate information retrieval that sets up the context for any LLM to improve its response to a given user prompt or query. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "We will be indexing abstracts for all astrophysics papers and Astropy's documentation, a common core package for Astronomy in Python. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "Embeddings, also called \"Vector Embedding,\" help LLMs develop a semantic understanding of the textual data they are trained on. In simpler terms, these embedding models lay the groundwork for LLMs to perform tasks like sentence completion, similarity search, questions and answers, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b50d479",
   "metadata": {},
   "source": [
    "#### Embedding vs Fine-tuning\n",
    "\n",
    "|| Embedding | Fine-tuning|\n",
    "|---|---|---|\n",
    "|**Definition**| Use pre-trained LLM as feature extractorâ€‹ | Update parameters of pre-trained LLM during task-specific training|\n",
    "|**Process**| Input Encoding > tokenizedâ€‹ > Embedding Extraction â€‹ > Downstream Task | Initialization â€‹> Task-specific Trainingâ€‹ > Fine-tuning Layers (optional)|\n",
    "|**Advantages**| Efficient use of pre-trained knowledge, Faster inference | Adaptability to task-specific nuances, May require less labeled data than from scratchâ€‹|\n",
    "|**Considerations**| N/A |Risk of overfitting, Computational cost can be high|\n",
    "|**When to use**| Limited computational resourcesâ€‹, Limited labeled data | Significant computational resources, Large corpus of labeled data|\n",
    "|**Performance**| Performs well, especially with limited dataâ€‹ | Can achieve state-of-the-art results on a wide range of tasks|\n",
    "\n",
    "### In a nutshell\n",
    "\n",
    "- Embeddings models are typically small in size and less computationally intensiveâ€‹\n",
    "\n",
    "- Regular updates of embedding vectors are faster, cheaper, and simpler compared to fine-tuning a model.â€‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "#### Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "At the lowest level, machines only understand numeric values. For LLMs to work, natural language is converted into an array of numeric values before they are fed into the models. These arrays of numeric values are called \"Vector.\"\n",
    "\n",
    "An example of a vector: [2.5, 1.0, 3.3, 7.8]\n",
    "\n",
    "The above is an example of a vector of size 4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector: [2.5 1.7 3.3 7.8]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "vector = np.array([2.5, 1.7, 3.3, 7.8])\n",
    "print(f\"Vector: {vector}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "#### Tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "We stated above that **\"texts are converted into an array of numeric values called vectors\"**.\n",
    "\n",
    "But depending on your use case, each word, sentence, paragraph, or entire document can be represented as a vector. \n",
    "\n",
    "Tokens are the smallest natural language units converted into a vector. It could be at the character level, sub-word level, word level, sentence level, paragraph level, or document level.\n",
    "\n",
    "Example: Consider the text below.\n",
    "\n",
    "`Earth is a planet of the solar system. There are 9 planets in the solar system. \n",
    "All planets revolve around the sun. Sun is a star.`\n",
    "\n",
    "\n",
    "Case 1.) **Tokenizing the entire paragraph into vector.**  \n",
    "Tokenization: The entire paragraph is a single token.   \n",
    "Vectorization: A single vector.  \n",
    "Sample Vector Representation: [3.1, 6.8, 5.4, 8.0, 7.1]\n",
    "\n",
    "Case 2.) **Tokenizing each sentence into vectors.**  \n",
    "Tokenization: One token for each sentence (total 4 tokens)  \n",
    "Vectorization: One vector for each sentence (total 4 vectors).   \n",
    "Sample Vector Representation: [[1.2, 2.3, 3.8, 7.9, 0.8], [2.5, 3.0, 8.2, 6.6, 4.1], [3.2, 6.5, 8.1, 9.3, 1.4], [1.1, 0.7, 7.2, 3.5, 8.5]]\n",
    "\n",
    "Case 3.) **Tokenizing each word in the paragraph into a vector. There are 26 words in the paragraph, ignoring punctuation. Each word gets converted into a vector.**  \n",
    "Tokenization: One token for each word in the paragraph (26 tokens)  \n",
    "Vectorization: One vector for each token (total 26 vectors).    \n",
    "Sample Vector Representation: [[2.1, 3.2, 4.1, 9.8, 7.0], [8.2, 4.2, 7.1, 3.8, 2.0].....total 26 such representations]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "#### Tokenizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "Tokenizers are components responsible for converting large texts into tokens (tokenization). Different types of pre-trained tokenizers are available. You can even train your own tokenizers. But for the scope of this tutorial, we will use a pre-trained one. \n",
    "\n",
    "Generally, each tokenizer follows the following steps:\n",
    "\n",
    "1. Break down the original text into tokens. These tokens could again be at the character, sub-word, word, sentence, paragraph, or document levels.\n",
    "2. Assign a unique identifier to each of the tokens created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For example, here is how you can split a short sentence into chunks of text\n",
    "from langchain_text_splitters import CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Earth is a', 'planet in', 'the solar', 'system.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\" \",\n",
    "    chunk_size=10,\n",
    "    chunk_overlap=0,\n",
    ")\n",
    "text_splitter.split_text(text=\"Earth is a planet in the solar system.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "[Learn more about how to split text into tokens in LangChain here.](https://python.langchain.com/v0.2/docs/how_to/split_by_token/) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "#### Embedding Models\n",
    "\n",
    "A language model needs to understand how tokens are related to each other in the context of human language. To understand this semantic relationship, these tokens are converted into numerical vectors.\n",
    "\n",
    "Embedding Models are trained upon these tokens to develop an \"embedding space.\"\n",
    "\n",
    "- Before the training, the embedding model initializes an N-dimensional 'vector' corresponding to each 'token' with random values. (Value of N depends on the embedding model)\n",
    "  \n",
    "- During the embedding model training, the values for these vectors are updated across iterations. In this process, similar or related tokens are updated to have similarly valued vectors.\n",
    "  \n",
    "- After the training, the collection of all the 'vectors' corresponding to all the tokens is called the \"embedding space.\"\n",
    "\n",
    "- \"Embedding Space\" is an encoded representation of meanings of tokens and inter-token relationships.\n",
    "\n",
    "See [Word Embeddings Resource](https://www.nlplanet.org/course-practical-nlp/01-intro-to-nlp/11-text-as-vectors-embeddings/) for more conceptual details on embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "To understand this further, let's take a look at how it all works using a pre-trained embedding model.\n",
    "\n",
    "For the tutorial and simplicity, we are using the Langchain Hugging Face integrations, which is available in the [`langchain-huggingface`](https://pypi.org/project/langchain-huggingface/) package.\n",
    "To use an embedding model available in Hugging Face,\n",
    "we will simply use the `HuggingFaceEmbedding` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cbbb3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f451a4ff",
   "metadata": {},
   "source": [
    "We are using the [all-MiniLM-L12-v2](https://huggingface.co/sentence-transformers/all-MiniLM-L12-v2) sentence-transformers embedding model for this tutorial.\n",
    "After [some evaluation](https://github.com/uw-ssec/tutorials/issues/6) that we did, we found that this model works well for our use case as it is lightweight and provides good performance.\n",
    "\n",
    "This model \"maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search\".\n",
    "\n",
    "However, you can use any other embedding model available in Hugging Face, and we recommend going to [MTEB Leaderboard](https://huggingface.co/spaces/mteb/leaderboard) to find embedding models and see how they compare to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lsetiawan/mambaforge/envs/ssec-scipy2024/lib/python3.11/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "# Setup the embedding, we are using the MiniLM model here\n",
    "embeddings_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L12-v2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_result = embeddings_model.embed_query(\"Earth is a planet in the solar system.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dimension of vector\n",
    "len(query_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.05409970134496689, 0.07589352875947952, -0.04195248335599899]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_result[-3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "In an embedding space, you can find how similar two vectors are using `dot product` or  using `cosine similarity.`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d5b4dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.7926038246541188\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Similarity:\",\n",
    "    1\n",
    "    - spatial.distance.cosine(\n",
    "        query_result,\n",
    "        embeddings_model.embed_query(\"Mars is a planet in the solar system.\"),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.08770959442668558\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Similarity:\",\n",
    "    1\n",
    "    - spatial.distance.cosine(\n",
    "        query_result, embeddings_model.embed_query(\"Hello Tacoma.\")\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1513a64",
   "metadata": {},
   "source": [
    "What we have demonstrated above in finding similarity between vectors is essentially what's happening in the retrieval phase of the RAG pipeline within a *Vector Database*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "#### Vector Stores\n",
    "\n",
    "Once the embeddings are created for our relevant documents or knowledge base, we need to store these embeddings in the database for fast retrieval. \n",
    "\n",
    "The type of databases that store these vector embeddings are called \"Vector Stores.\" We will use a vector store called \"Qdrant,\" as shown below. \n",
    "\n",
    "In the below code, \n",
    "- Vector store works along with the embedding model to create vector embeddings.\n",
    "- Vector embeddings are stored in the Qdrant Vector database collection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "We have already created a vector database that contains the astrophysics paper abstracts and Astropy's documentation, please refer to the [notebook](../appendix/astrophysics-dataset-creation.ipynb) in the Appendix.\n",
    "\n",
    "The `ssec_tutorials` utility package contains a `download_qdrant_data` function that downloads the existing Qdrant database that we've created for this tutorial.\n",
    "Additionally, there's a `QDRANT_COLLECTION_NAME` constant variable\n",
    "that contains the name of the collection in the Qdrant database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de21b9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ssec_tutorials import download_qdrant_data, QDRANT_COLLECTION_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qdrant data already exists at /Users/lsetiawan/.cache/ssec_tutorials/scipy_qdrant\n"
     ]
    }
   ],
   "source": [
    "QDRANT_PATH = download_qdrant_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bacdd0af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/lsetiawan/.cache/ssec_tutorials/scipy_qdrant')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QDRANT_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arxiv_astro-ph_abstracts_astropy_github_documentation'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QDRANT_COLLECTION_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bc7155",
   "metadata": {},
   "source": [
    "With having the Qdrant path and collection name information, as well as the embeddings model, we can now use the Langchain Qdrant integrations package called `langchain-qdrant` to interact with the Qdrant database by using the `Qdrant` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a3744c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_qdrant import Qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6eae38d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant = Qdrant.from_existing_collection(\n",
    "    embedding=embeddings_model,\n",
    "    collection_name=QDRANT_COLLECTION_NAME,\n",
    "    path=QDRANT_PATH,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "### Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e73d977",
   "metadata": {},
   "source": [
    "Now that we have the Qdrant database instance, we are ready to search for the relevant documents based on the user query.\n",
    "However, before we can simply search, we will need a [`VectorStoreRetriever`](https://python.langchain.com/v0.2/docs/how_to/vectorstore_retriever/) object.\n",
    "\n",
    "To get the `VectorStoreRetriever` object, we can simply call the `.as_retriever()` method on the Qdrant object.\n",
    "\n",
    "In this example, we will be setting the `search_type` to `\"mmr\"` and `search_kwargs` to `{\"k\": 2}`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7aa006",
   "metadata": {},
   "source": [
    "\"mmr\" stands for  Maximum Marginal Relevance\n",
    "\n",
    "MMR selects examples based on a combination of which examples are most similar to the inputs, while also optimizing for diversity. It does this by finding the examples with the embeddings that have the greatest cosine similarity with the inputs, and then iteratively adding them while penalizing them for closeness to already selected examples.\n",
    "\n",
    "The `k` parameter in `search_kwargs` specifies the number of documents to retrieve.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the retriever for later step\n",
    "retriever = qdrant.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 2})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf703bba",
   "metadata": {},
   "source": [
    "Let's invoke this retriever object with some of the questions from previous section and see what we get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = retriever.invoke(\"What is dark matter?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f9512a",
   "metadata": {},
   "source": [
    "We got the relevant documents from the Qdrant database for the given questions. Let's see what these documents look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "04949b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "document = documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e641df5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.documents.base.Document"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ac457806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'page_content': '  One of the great scientific enigmas still unsolved, the existence of dark\\nmatter, is reviewed. Simple gravitational arguments imply that most of the mass\\nin the Universe, at least 90%, is some (unknown) non-luminous matter. Some\\nparticle candidates for dark matter are discussed with particular emphasis on\\nthe neutralino, a particle predicted by the supersymmetric extension of the\\nStandard Model of particle physics. Experiments searching for these relic\\nparticles, carried out by many groups around the world, are also discussed.\\nThese experiments are becoming more sensitive every year and in fact one of the\\ncollaborations claims that the first direct evidence for dark matter has\\nalready been observed.\\n',\n",
       " 'metadata': {'id': 'hep-ph/0110122',\n",
       "  'title': 'The Enigma of the Dark Matter',\n",
       "  '_id': '4ab99f7c922747d9a6a34b855d959779',\n",
       "  '_collection_name': 'arxiv_astro-ph_abstracts_astropy_github_documentation'},\n",
       " 'type': 'Document'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d66587e",
   "metadata": {},
   "source": [
    "We see that this is a core Langchain Document object that contains the document's metadata and content.\n",
    "\n",
    "Later we will see how we can use this document to generate the response, for now let's create a utility formatting function to retrieve just the content of the document so that we can put this as part of our prompt template input, also known as \"Augmentation\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post-processing\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  One of the great scientific enigmas still unsolved, the existence of dark\n",
      "matter, is reviewed. Simple gravitational arguments imply that most of the mass\n",
      "in the Universe, at least 90%, is some (unknown) non-luminous matter. Some\n",
      "particle candidates for dark matter are discussed with particular emphasis on\n",
      "the neutralino, a particle predicted by the supersymmetric extension of the\n",
      "Standard Model of particle physics. Experiments searching for these relic\n",
      "particles, carried out by many groups around the world, are also discussed.\n",
      "These experiments are becoming more sensitive every year and in fact one of the\n",
      "collaborations claims that the first direct evidence for dark matter has\n",
      "already been observed.\n",
      "\n",
      "\n",
      "  Dark matter could be composed of compact dark objects (CDOs). These objects\n",
      "may interact very weakly with normal matter and could move freely {\\it inside}\n",
      "the Earth. A CDO moving in the inner core of the Earth will have an orbital\n",
      "period near 55 min and produce a time dependent signal in a gravimeter. Data\n",
      "from superconducting gravimeters rule out such objects moving inside the Earth\n",
      "unless their mass $m_D$ and or orbital radius $a$ are very small so that $m_D\\,\n",
      "a < 1.2\\times 10^{-13}M_\\oplus R_\\oplus$. Here $M_\\oplus$ and $R_\\oplus$ are\n",
      "the mass and radius of the Earth.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(format_docs(documents))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {},
   "source": [
    "## Augmentation & Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {},
   "source": [
    "Now that we can retrieve the most relevant document based on a question, we can use the retrieved document and send it along with the prompt to increase the context for the LLM.\n",
    "\n",
    "This can also be referred to as the `retrieval-augmented prompt.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2198c395",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import LlamaCpp\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from ssec_tutorials import download_olmo_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fa77cf1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model already exists at /Users/lsetiawan/.cache/ssec_tutorials/OLMo-7B-Instruct-Q4_K_M.gguf\n"
     ]
    }
   ],
   "source": [
    "OLMO_MODEL = download_olmo_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "olmo = LlamaCpp(\n",
    "    model_path=str(OLMO_MODEL),\n",
    "    temperature=0.8,\n",
    "    verbose=False,\n",
    "    n_ctx=2048,\n",
    "    max_tokens=512,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a prompt template using OLMo's tokenizer chat template we saw in module 1.\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    template=olmo.client.metadata[\"tokenizer.chat_template\"],\n",
    "    template_format=\"jinja2\",\n",
    "    partial_variables={\"add_generation_prompt\": True, \"eos_token\": \"<|endoftext|>\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the prompt you want to send to OLMo.\n",
    "question = \"What is dark matter?\"\n",
    "context = format_docs(retriever.invoke(question))\n",
    "\n",
    "final_prompt_content = prompt_template.format(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"\\\n",
    "                You are an astrophysics expert. Please answer the question on astrophysics based on the following context:\n",
    "\n",
    "                Context: {context}\n",
    "\n",
    "                Question: {question}\n",
    "            \"\"\",\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8bee04b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|endoftext|>\n",
      "\n",
      "<|user|>\n",
      "                You are an astrophysics expert. Please answer the question on astrophysics based on the following context:\n",
      "\n",
      "                Context:   One of the great scientific enigmas still unsolved, the existence of dark\n",
      "matter, is reviewed. Simple gravitational arguments imply that most of the mass\n",
      "in the Universe, at least 90%, is some (unknown) non-luminous matter. Some\n",
      "particle candidates for dark matter are discussed with particular emphasis on\n",
      "the neutralino, a particle predicted by the supersymmetric extension of the\n",
      "Standard Model of particle physics. Experiments searching for these relic\n",
      "particles, carried out by many groups around the world, are also discussed.\n",
      "These experiments are becoming more sensitive every year and in fact one of the\n",
      "collaborations claims that the first direct evidence for dark matter has\n",
      "already been observed.\n",
      "\n",
      "\n",
      "  Dark matter could be composed of compact dark objects (CDOs). These objects\n",
      "may interact very weakly with normal matter and could move freely {\\it inside}\n",
      "the Earth. A CDO moving in the inner core of the Earth will have an orbital\n",
      "period near 55 min and produce a time dependent signal in a gravimeter. Data\n",
      "from superconducting gravimeters rule out such objects moving inside the Earth\n",
      "unless their mass $m_D$ and or orbital radius $a$ are very small so that $m_D\\,\n",
      "a < 1.2\\times 10^{-13}M_\\oplus R_\\oplus$. Here $M_\\oplus$ and $R_\\oplus$ are\n",
      "the mass and radius of the Earth.\n",
      "\n",
      "\n",
      "                Question: What is dark matter?\n",
      "            \n",
      "\n",
      "\n",
      "<|assistant|>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(final_prompt_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073742e1",
   "metadata": {},
   "source": [
    "You can see above that we now have a `context` input within the prompt.\n",
    "This context is the content of the document(s) that we retrieved from the Qdrant database.\n",
    "With this context, the LLM can generate more relevant responses.\n",
    "So let's see how it does!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c23cfea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.callbacks import StreamingStdOutCallbackHandler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26449257",
   "metadata": {},
   "source": [
    "### OLMo with context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5030cd5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dark matter is a theoretical component of the Universe that has yet to be directly observed but its presence can be inferred from the gravitational effects it exerts on visible matter such as stars, gas, and galaxies. According to current astrophysical data, approximately 90% of the content in the universe is dark matter, while only 5% is made up of visible, or baryonic, matter (stars, gas, and dust). Dark matter particles are yet to be directly observed; their existence is inferred from their gravitational effects on visible objects.\n",
      "\n",
      "One candidate for dark matter is the neutralino, a particle predicted by the supersymmetric extension of the Standard Model of particle physics. Neutralinos have several properties that make them an appealing choice as dark matter candidates. First, they are stable and can persist in the universe until today. Second, they are non-interacting with ordinary matter particles, allowing them to move freely within planets like Earth without being affected by their gravity.\n",
      "\n",
      "CDOs (Compact Dark Objects) are a possible explanation for the gravitational effects attributed to dark matter. CDOs are hypothetical objects that have been proposed to interact weakly with normal matter and can move freely inside a planet or other large celestial bodies, such as the Earth's inner core. However, their presence in the Earth's inner core is constrained by the data from superconducting gravimeters; they must have masses $m_D\\, a < 1.2\\times 10^{-13}M_\\oplus R_\\oplus$, where M_\\oplus and R_\\oplus are the mass and radius of the Earth, respectively.\n",
      "\n",
      "It's important to remember that this is just one possibility for the existence of dark matter and there might be other types or forms of dark matter in the universe. As more data becomes available from experiments searching for dark matter relics, scientists will continue to refine their models and searches to better understand its nature."
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" Dark matter is a theoretical component of the Universe that has yet to be directly observed but its presence can be inferred from the gravitational effects it exerts on visible matter such as stars, gas, and galaxies. According to current astrophysical data, approximately 90% of the content in the universe is dark matter, while only 5% is made up of visible, or baryonic, matter (stars, gas, and dust). Dark matter particles are yet to be directly observed; their existence is inferred from their gravitational effects on visible objects.\\n\\nOne candidate for dark matter is the neutralino, a particle predicted by the supersymmetric extension of the Standard Model of particle physics. Neutralinos have several properties that make them an appealing choice as dark matter candidates. First, they are stable and can persist in the universe until today. Second, they are non-interacting with ordinary matter particles, allowing them to move freely within planets like Earth without being affected by their gravity.\\n\\nCDOs (Compact Dark Objects) are a possible explanation for the gravitational effects attributed to dark matter. CDOs are hypothetical objects that have been proposed to interact weakly with normal matter and can move freely inside a planet or other large celestial bodies, such as the Earth's inner core. However, their presence in the Earth's inner core is constrained by the data from superconducting gravimeters; they must have masses $m_D\\\\, a < 1.2\\\\times 10^{-13}M_\\\\oplus R_\\\\oplus$, where M_\\\\oplus and R_\\\\oplus are the mass and radius of the Earth, respectively.\\n\\nIt's important to remember that this is just one possibility for the existence of dark matter and there might be other types or forms of dark matter in the universe. As more data becomes available from experiments searching for dark matter relics, scientists will continue to refine their models and searches to better understand its nature.\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "olmo.invoke(\n",
    "    final_prompt_content, config={\"callbacks\": [StreamingStdOutCallbackHandler()]}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb26355",
   "metadata": {},
   "source": [
    "### OLMo without context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "422daa7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " What is dark energy?\n",
      "These are two of the most interesting, and perhaps most important, questions in modern physics. In this episode of SciFri we explore what these mysterious substances might be, and why they have such a big impact on our understanding of the universe.\n",
      "Dark Matter is a mysterious substance that seems to make up about 85% of the matter in the Universe. It doesn't interact with light or energy, but it does interact with gravity. This means that it affects how galaxies spin, and it also leaves its mark on the way that stars move through the Milky Way. Scientists believe that Dark Matter is a substance made from something called WIMPs - Weakly Interacting Massive Particles.\n",
      "Dark Energy, on the other hand, is a mysterious force in the Universe that seems to be pushing the cosmos apart at an ever-increasing rate. It makes up about 68% of the energy in the universe. Scientists think that Dark Energy might be caused by something called \"chocolate\" - a substance that acts like a negative pressure, pulling things apart even faster than gravity.\n",
      "Join SciFri's Gerry Canavan and Dr Emma Krumholz as they dive deep into the mysteries of Dark Matter and Dark Energy to see what we can learn about the universe."
     ]
    },
    {
     "data": {
      "text/plain": [
       "' What is dark energy?\\nThese are two of the most interesting, and perhaps most important, questions in modern physics. In this episode of SciFri we explore what these mysterious substances might be, and why they have such a big impact on our understanding of the universe.\\nDark Matter is a mysterious substance that seems to make up about 85% of the matter in the Universe. It doesn\\'t interact with light or energy, but it does interact with gravity. This means that it affects how galaxies spin, and it also leaves its mark on the way that stars move through the Milky Way. Scientists believe that Dark Matter is a substance made from something called WIMPs - Weakly Interacting Massive Particles.\\nDark Energy, on the other hand, is a mysterious force in the Universe that seems to be pushing the cosmos apart at an ever-increasing rate. It makes up about 68% of the energy in the universe. Scientists think that Dark Energy might be caused by something called \"chocolate\" - a substance that acts like a negative pressure, pulling things apart even faster than gravity.\\nJoin SciFri\\'s Gerry Canavan and Dr Emma Krumholz as they dive deep into the mysteries of Dark Matter and Dark Energy to see what we can learn about the universe.'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "olmo.invoke(question, config={\"callbacks\": [StreamingStdOutCallbackHandler()]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a35bf4",
   "metadata": {},
   "source": [
    "From the responses above, we can see that the response with context is more relevant and informative compared to the response without context, an this shows the power of the RAG framework, with just a few documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56",
   "metadata": {},
   "source": [
    "One way to generate the response with OLMo is to build `context` using the `question` beforehand, as shown above, create an llm_chain then `invoke` it with `messages`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59",
   "metadata": {},
   "source": [
    "However, We can further use [LangChain's convenience functions](https://python.langchain.com/v0.2/docs/tutorials/rag/#built-in-chains) to streamline our pipeline using [create_stuff_documents_chain](https://api.python.langchain.com/en/latest/chains/langchain.chains.combine_documents.stuff.create_stuff_documents_chain.html) and [create_retrieval_chain](https://api.python.langchain.com/en/latest/chains/langchain.chains.retrieval.create_retrieval_chain.html) from the main `langchain` package.\n",
    "\n",
    "The main `langchain` package contains chains, agents, and retrieval strategies that make up an application's cognitive architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60",
   "metadata": {},
   "source": [
    "`create_stuff_documents_chain` specifies how retrieved context is fed into a prompt and LLM. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61",
   "metadata": {},
   "source": [
    "On looking its signature, notice that it accepts `prompt` argument of type `BasePromptTemplate` but it needs input keys as `context` and `input`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "205799a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51e663f",
   "metadata": {},
   "source": [
    "To use the helper functions,\n",
    "we'll need to setup our template string to use the `context` and `input` keys as variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['context', 'input'], template='<|endoftext|>\\n\\n<|user|>\\nYou are an astrophysics expert. Please answer the question on astrophysics based on the following context.\\nContext: {context}\\nQuestion: {input}\\n\\n\\n\\n<|assistant|>\\n\\n')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new prompt_template\n",
    "# so that it accepts `context` and `input` as input_variables\n",
    "input_string_template = \"\"\"\\\n",
    "You are an astrophysics expert. Please answer the question on astrophysics based on the following context.\n",
    "Context: {context}\n",
    "Question: {input}\n",
    "\"\"\"\n",
    "transformed_prompt_template = PromptTemplate.from_template(\n",
    "    prompt_template.partial(\n",
    "        messages=[{\"role\": \"user\", \"content\": input_string_template}]\n",
    "    ).format()\n",
    ")\n",
    "transformed_prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_chain = create_stuff_documents_chain(\n",
    "    llm=olmo, prompt=transformed_prompt_template\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65",
   "metadata": {},
   "source": [
    "We can run this by passing in the context directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dark matter is a theoretical entity that is still not directly observed or detected in our universe. Based on current scientific understanding, it makes up approximately 90% of the matter content in the observable Universe (1). The term \"dark\" refers to its invisible nature; it does not emit, reflect, nor absorb light and cannot be seen with conventional telescopes.\n",
      "\n",
      "One possible explanation for dark matter is that it comprises weakly interacting massive particles (WIMPs), which are hypothetical particles predicted by theoretical physics. Although they have yet to be discovered, WIMPs could account for the missing mass in our Universe. Some particle candidates for dark matter include the neutralino mentioned in the context, which is a stable superluminous particle that can naturally acquire a tiny electric charge without violating energy conservation laws (2).\n",
      "\n",
      "The existence of dark matter is supported by several astronomical and cosmological observations. These include the rotation curves of galaxies, where dark matter's gravitational pull dominates over visible matter; the cosmic microwave background radiation (CMBR) mapping, which reveals the distribution of matter in the Universe based on its temperature; and the large-scale structure formation, which highlights the non-uniform distribution of visible matter clusters.\n",
      "\n",
      "Although direct detection of dark matter particles remains a challenge, ongoing experiments searching for these particles have become more sensitive every year (3). For instance, a collaboration reported the first indirect evidence of dark matter's existence via gravitational lensing effects on starlight (4). Moreover, superconducting gravimeters can detect signals from compact dark objects (CDOs) within Earth's inner core. However, they require small mass ($m_D\\approx 1.2\\times 10^{-13}M_\\oplus R_\\oplus$) and orbital radius ($a\\approx 1\\times10^{23}-1\\times10^{24} m$) to satisfy the constraints (5).\n",
      "\n",
      "In conclusion, dark matter is a fundamental concept in modern cosmology that remains an active research topic. Its nature remains unknown due to its invisible properties, yet it continues to be studied and sought after to better understand our cosmic composition and structure."
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Dark matter is a theoretical entity that is still not directly observed or detected in our universe. Based on current scientific understanding, it makes up approximately 90% of the matter content in the observable Universe (1). The term \"dark\" refers to its invisible nature; it does not emit, reflect, nor absorb light and cannot be seen with conventional telescopes.\\n\\nOne possible explanation for dark matter is that it comprises weakly interacting massive particles (WIMPs), which are hypothetical particles predicted by theoretical physics. Although they have yet to be discovered, WIMPs could account for the missing mass in our Universe. Some particle candidates for dark matter include the neutralino mentioned in the context, which is a stable superluminous particle that can naturally acquire a tiny electric charge without violating energy conservation laws (2).\\n\\nThe existence of dark matter is supported by several astronomical and cosmological observations. These include the rotation curves of galaxies, where dark matter\\'s gravitational pull dominates over visible matter; the cosmic microwave background radiation (CMBR) mapping, which reveals the distribution of matter in the Universe based on its temperature; and the large-scale structure formation, which highlights the non-uniform distribution of visible matter clusters.\\n\\nAlthough direct detection of dark matter particles remains a challenge, ongoing experiments searching for these particles have become more sensitive every year (3). For instance, a collaboration reported the first indirect evidence of dark matter\\'s existence via gravitational lensing effects on starlight (4). Moreover, superconducting gravimeters can detect signals from compact dark objects (CDOs) within Earth\\'s inner core. However, they require small mass ($m_D\\\\approx 1.2\\\\times 10^{-13}M_\\\\oplus R_\\\\oplus$) and orbital radius ($a\\\\approx 1\\\\times10^{23}-1\\\\times10^{24} m$) to satisfy the constraints (5).\\n\\nIn conclusion, dark matter is a fundamental concept in modern cosmology that remains an active research topic. Its nature remains unknown due to its invisible properties, yet it continues to be studied and sought after to better understand our cosmic composition and structure.'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What is dark matter?\"\n",
    "document_chain.invoke(\n",
    "    {\n",
    "        \"input\": question,\n",
    "        \"context\": retriever.invoke(question),\n",
    "    },\n",
    "    config={\"callbacks\": [StreamingStdOutCallbackHandler()]},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67",
   "metadata": {},
   "source": [
    "However, we want the context to be dynamically generated using the passed input or question."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68",
   "metadata": {},
   "source": [
    "From LangChain's documentation: `create_retrieval_chain` adds the retrieval step and propagates the retrieved context through the chain, providing it alongside the final answer. It has input key `input`, and includes input, context, and answer in its output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dark matter is a theoretical entity that is still not directly observed or detected in our universe, despite its significant presence based on gravitational arguments and astronomical observations. According to astrophysics, approximately 90% of the visible mass in the Universe is believed to be non-luminous dark matter, which does not emit, reflect, or absorb light. Dark matter particles are yet to be discovered, but they have been predicted by particle physics based on supersymmetry (SUSY). SUSY predicts that dark matter can take various forms such as the neutralino, a particle that is an inert supersymmetric partner of the known photon and lepton particles.\n",
      "\n",
      "The term \"dark\" refers to its inability to be detected or observed using electromagnetic radiation, making it difficult to study directly. Dark matter could exist in various forms like compact dark objects (CDOs) - hypothetical particles with no interaction with normal matter, moving freely inside Earth, and producing a time-dependent signal in a gravimeter due to their low mass and orbital radius.\n",
      "\n",
      "Despite numerous experiments searching for evidence of dark matter, it remains an enigmatic scientific mystery. However, recent observations claim the first direct evidence of dark matter, which highlights the ongoing efforts to uncover this mysterious substance."
     ]
    }
   ],
   "source": [
    "response = retrieval_chain.invoke(\n",
    "    {\"input\": \"What is dark matter?\"},\n",
    "    config={\"callbacks\": [StreamingStdOutCallbackHandler()]},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'What is dark matter?',\n",
       " 'context': [Document(page_content='  One of the great scientific enigmas still unsolved, the existence of dark\\nmatter, is reviewed. Simple gravitational arguments imply that most of the mass\\nin the Universe, at least 90%, is some (unknown) non-luminous matter. Some\\nparticle candidates for dark matter are discussed with particular emphasis on\\nthe neutralino, a particle predicted by the supersymmetric extension of the\\nStandard Model of particle physics. Experiments searching for these relic\\nparticles, carried out by many groups around the world, are also discussed.\\nThese experiments are becoming more sensitive every year and in fact one of the\\ncollaborations claims that the first direct evidence for dark matter has\\nalready been observed.\\n', metadata={'id': 'hep-ph/0110122', 'title': 'The Enigma of the Dark Matter', '_id': '4ab99f7c922747d9a6a34b855d959779', '_collection_name': 'arxiv_astro-ph_abstracts_astropy_github_documentation'}),\n",
       "  Document(page_content='  Dark matter could be composed of compact dark objects (CDOs). These objects\\nmay interact very weakly with normal matter and could move freely {\\\\it inside}\\nthe Earth. A CDO moving in the inner core of the Earth will have an orbital\\nperiod near 55 min and produce a time dependent signal in a gravimeter. Data\\nfrom superconducting gravimeters rule out such objects moving inside the Earth\\nunless their mass $m_D$ and or orbital radius $a$ are very small so that $m_D\\\\,\\na < 1.2\\\\times 10^{-13}M_\\\\oplus R_\\\\oplus$. Here $M_\\\\oplus$ and $R_\\\\oplus$ are\\nthe mass and radius of the Earth.\\n', metadata={'id': 1912.0094, 'title': 'Gravimeter search for compact dark matter objects moving in the Earth', '_id': '97fa0dcbd2aa45d28dfccaa150e724e2', '_collection_name': 'arxiv_astro-ph_abstracts_astropy_github_documentation'})],\n",
       " 'answer': 'Dark matter is a theoretical entity that is still not directly observed or detected in our universe, despite its significant presence based on gravitational arguments and astronomical observations. According to astrophysics, approximately 90% of the visible mass in the Universe is believed to be non-luminous dark matter, which does not emit, reflect, or absorb light. Dark matter particles are yet to be discovered, but they have been predicted by particle physics based on supersymmetry (SUSY). SUSY predicts that dark matter can take various forms such as the neutralino, a particle that is an inert supersymmetric partner of the known photon and lepton particles.\\n\\nThe term \"dark\" refers to its inability to be detected or observed using electromagnetic radiation, making it difficult to study directly. Dark matter could exist in various forms like compact dark objects (CDOs) - hypothetical particles with no interaction with normal matter, moving freely inside Earth, and producing a time-dependent signal in a gravimeter due to their low mass and orbital radius.\\n\\nDespite numerous experiments searching for evidence of dark matter, it remains an enigmatic scientific mystery. However, recent observations claim the first direct evidence of dark matter, which highlights the ongoing efforts to uncover this mysterious substance.'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b91fe4",
   "metadata": {},
   "source": [
    "One of the nice things about the LangChain helper function is that the result is a dictionary containing the `input`, `context`, and `answer` keys, so you can easily see what you asked and the context that was used to generate the answer.\n",
    "\n",
    "This way of creating the RAG pipeline is quick, but not as customizable. If you need more control over the input variables, we'll need to create our own chain.\n",
    "\n",
    "In the next module, we'll explore how to do this to create a simple Panel application that uses the RAG pipeline to generate responses to user questions.\n",
    "\n",
    "For now let's clean up the qdrant client by closing it before the next module, otherwise we'll run into errors!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4a9d42bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant.client.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
